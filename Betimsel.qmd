# Betimsel İstatistik {#sec-betimsel}

İstatistiksel analizin önemli aşamalarından biri verilerin betimlenmesi ve özetlenmesidir. Betimsel istatistik verilerin çeşitli sayısal ve görsel araçlar yardımıyla özetlenmesi ile uğraşır. Bu bölümde, veri kümelerinin temel özelliklerini tanımlamada yaygın olarak kullanılan sayısal ve görsel yöntemleri inceleyeceğiz. Bu yöntemler, veri kümesinin genel yapısını anlamaya ve sayısal bilgi yığınlarındaki gizli örüntüleri, ilişkileri ve sıra dışı davranışları tanımlamaya yardımcı olur. Betimsel istatistiklerin kullanımı, verinin türünden veya büyüklüğünden bağımsız olarak faydalıdır. Küçük veri setlerinden büyük veri tabanlarına kadar her türlü veri üzerinde kullanılabilir. Görgül bilimsel verilerle çalışmaya başlamanın ilk adımı betimsel istatistiklerin incelenmesidir. Bu analizler, verileriniz hakkında genel bir anlayış sağlar ve daha karmaşık analitik tekniklerin temelini oluşturur.

Bu bölümde, ilk olarak veri kümelerinin ve değişkenlerin özelliklerini ele alacağız. Daha sonra verilerin merkezi eğilimini (ortalama, medyan, mod) ve değişkenliğini (standart sapma, varyans) ölçmeye yönelik temel teknikleri inceleyeceğiz. Ayrıca, veri dağılımını görselleştirmek için histogramlar, kutu grafikleri ve diğer grafik türlerini nasıl kullanacağımızı öğreneceğiz. 


## Anakütle ve Örneklem 

Bir veri kümesi ilgilendiğimiz birimlere ilişkin ölçümlerden ya da kayıtlardan oluşur. Gözlem birimi kişi, hanehalkı, tüketici, firma, şehir, bölge, ülke vb olabilir. Pratikte karşılaştığımız veri kümeleri, tüm birimlerin verilerini içeren bir **anakütle** ya da bu birimlerin belirli bir kısmını kapsayan bir **örneklem** olabilir. 

::: {#def-anakutle}

## Anakütle (popülasyon, evren)

Araştırma yapılan birim ya da nesnelere ilişkin eksiksiz veri kümesine anakütle (ya da evren/popülasyon) adı verilir. Anakütle, araştırma sorusuyla doğrudan ilgilidir ve genellikle çok geniş bir veri kümesini temsil eder. 
:::

Bir ülke ya da şehirdeki tüm hanehalkları, bir üniversitedeki tüm öğrenciler, bir endüstrideki tüm çalışanlar ya da bir fabrikada bir günde üretilen tüm ürünler anakütleyi oluşturabilir. Anakütle genellikle çok büyük olduğundan, her birimi gözlemlemek zor veya yüksek maliyetli olabilir. Bu durum, araştırmacıları birimlerin tamamını gözlemlemek yerine anakütlenin bir alt kümesi olan **örneklem** ile çalışmaya yönlendirir. İstatistiksel çıkarsamanın temel amacı, örneklem verilerinden hareketle anakütle hakkında bilgi edinmek ve genellemeler yapmaktır.  


::: {#def-parametre}

## Parametre 

Anakütleyi tanımlayan ve anakütlenin belirli bir özelliğine ilişkin bilgi içeren **sabit değerlere parametre** denir. Örneğin, Türkiye'deki tüm hanehalklarının ortalama geliri bir parametredir. Bir fabrikanın tüm ürünlerinin ortalama ağırlığı veya bir okuldaki tüm öğrencilerin başarı ortalaması birer parametredir.
:::

Anakütle doğrudan gözlenemiyorsa parametreleri hesaplamak mümkün olmaz. Anakütle hakkında çıkarım yapmanın ve bilinmeyen parametreleri tahmin etmenin bir yolu anakütlenin tamamını gözlemlemek yerine daha küçük bir alt kümesine ilişkin bilgi toplamaktır. 

::: {#def-orneklem}

## Örneklem

Anakütle hakkında bilgi edinmek amacıyla belirli yöntemlerle seçilen anakütlenin bir alt kümesine örneklem (*sample*) adı verilir.  
:::

Örneklem anakütleden daha küçük olduğu için bilgi toplamak daha kolay ve ucuzdur. Bir şehirde yaşayan tüm hanelere ulaşmak yerine, bu anakütleyi temsil edebilen 500 gözlemli bir örneklem oluşturulabilir. Toplam öğrenci sayısı 40000 olan bir üniversitede, tesadüfi olarak seçilmiş 100 öğrenciden oluşan bir örneklem kullanılarak çıkarım ve genellemeler yapılabilir. 

::: {#def-istatistik}

## İstatistik

Örneklemden hesaplanan ve anakütle parametrelerini tahmin etmek için kullanılan değerlere **istatistik** denir. İstatistikler, örneklem verilerinden elde edilen ve anakütle hakkında bilgi veren ölçümlerdir. Örneğin, bir şehirdeki rassal seçilmiş 1000 hanehalkının ortalama geliri, bir üniversitedeki 200 öğrencinin ortalama notu veya bir fabrikada üretilen 500 ürünün ortalama ağırlığı birer istatistiktir.
:::

Parametre ile istatistik birbiriyle karıştırılmamalıdır. Parametre anakütleye ilişkin sabitlerdir ve genellikle pratikte bilinmezler. İstatistikler ise örnekleme ilişkin değerlerdir ve sabit değildir. Başka bir örneklem çektiğimizde istatistikler de değişir. İstatistikleri rassal (tesadüfi) değişken olarak düşünebiliriz. 

Anakütlenin daha küçük bir temsili olarak düşünebileceğimiz örneklemi uygun yöntemlerle inceleyerek anakütle hakkında genellemeler ve çıkarımlar yapabiliriz. 
Temsili bir örneklem, anakütlenin özelliklerini doğru bir şekilde yansıtmalıdır. Örneklem ne kadar iyi seçilirse, anakütle hakkında o kadar güvenilir genellemeler yapılabilir. Yanlış veya eksik bir örneklem, yanıltıcı sonuçlara ve yanlış çıkarımlara yol açabilir.

Anakütleden örneklem almanın çok çeşitli yolları vardır. En sık kullanılan iki yöntem **basit rassal örnekleme** ve **tabakalı örnekleme**dir. Basit rassal örneklemede her birimin örneklemde olma olasılığı eşittir. Tabakalı örneklemede,  anakütle belirli özelliklere göre homojen alt gruplara (tabakalara) ayrılır ve her tabaka içinde rassal örneklemler çekilir. Örneğin, bir okulda öğrenci gruplarını sınıf düzeylerine göre (9. sınıf, 10. sınıf, vb.) ayırarak her sınıftan belirli sayıda öğrenci seçilerek anakütlenin daha iyi temsil edilmesi sağlanabilir. Bunlara ek olarak, küme örneklemesi ve sistematik örnekleme gibi daha ileri örnekleme teknikleri de mevcuttur. Bu yöntemler, anakütlenin yapısına ve araştırmanın amacına bağlı olarak tercih edilebilir.

Bu bölümde inceleyeceğimiz araçlar veri kümesinin anakütle mi yoksa örneklem mi olduğuna göre değişebilir. Ancak çoğu kavram ve araç her iki veri türüne de uygulanabilir. Bazı kavram ve araçların tanımları anakütle ve örneklem için ayrı ayrı yapılmıştır.  

Anakütle ya da örneklem verileri bilgisayarlarda çeşitli biçimlerde işlenebilir (vektör, liste, matris, veri çerçeveleri vb). Pratikte yaygın olarak bir *spreadsheet* formatında ya da `R`'ın veri çerçeveleri formatında saklayabiliriz. Bir veri çerçevesi yapı olarak spreadsheet formatına benzer. Satırlarda gözlem birimleri ve sütunlarda değişkenler yer alır. Hücrelerde ise gözlem değerleri bulunur. Örneğin tüm hanehalklarından oluşan bir anakütleden çekilmiş 2000 gözlemli bir rassal örneklem: 

```{r}
load("Data/hane_ornek.RData")
str(hane_ornek)
```
Bu veri kümesinde hanede yaşayan kişi sayısı, hanenin yıllık ve aylık geliri ve harcaması, tasarruf yapıp yapmadığı gibi çeşitli bilgiler bulunmaktadır. 

```{r}
head(hane_ornek[,1:6])
```

Sütunlarda yer alan değişkenler gözlem birimlerine (hanehalklarına) ilişkin çeşitli bilgiler içerir. Hanehalkı bir adreste (konutta) yaşayan tüm bireylerden oluşan topluluk olarak tanımlanır.  Yukarıdaki örnekte, birinci satırdaki 7373 numaralı hanehalkı 3 kişiden oluşmaktadır, yıllık geliri 61379 TL'dir ve tasarruf yapmaktadır. 2483 numaralı hanehalkı ise 6 kişiden oluşmaktadır, yıllık geliri 55287 TL'dir ve tasarruf yapmamaktadır. 

Tipik olarak bu veriler gözlem birimleriyle yapılan anketlerle toplanır. İktisatta ve diğer sosyal bilim alanlarında kullanılan verilerin önemli bir kısmı, anket ve araştırma sonuçlarına dayanmaktadır. Türkiye'de bu tür verilerin en önemli kaynaklarından biri **Türkiye İstatistik Kurumu (TÜİK)**'dur. TÜİK, hem makro hem de mikro düzeyde veri üretmek için düzenli aralıklarla çeşitli anketler ve araştırmalar gerçekleştirir. Mikro veriler, bireyler, hanehalkları veya firmalar gibi küçük birimlerin davranışlarını anlamak için kullanılır ve iktisadi analizlerde yaygın olarak kullanılır. 

TÜİK'in iktisatta sıkça kullanılan mikro verileri topladığı başlıca anketler ve veri kümeleri şunlardır:

  - **Hanehalkı İşgücü Araştırması** (HİA): Türkiye'de işgücü piyasasına ilişkin istatistikleri üretmek amacıyla yapılan bu anket, işgücü, istihdam, işsizlik ve işgücüne katılım gibi temel göstergeleri sağlar.  
  
  - **Hanehalkı Bütçe Araştırması** (HBA): Hanehalklarının gelir, tüketim ve harcama alışkanlıklarını ölçmek için yapılan bu anket, gelir dağılımı, yoksulluk ve tüketim eğilimleri gibi önemli konularda veri sunar. Hanehalkı tüketim sepeti ve ağırlıkları HBA ile belirlenir ve tüketici fiyat endeksinin hesaplanmasında kullanılır.   
  
  - **Gelir ve Yaşam Koşulları Araştırması** (GYKA): Hanehalklarının gelir kaynakları, yaşam standartları ve yoksulluk durumlarına ilişkin bilgi sağlayan bu anket, gelir eşitsizliği, sosyal hareketlilik ve refah düzeyini ölçmeye yönelik detaylı veriler içerir.
  
  - **Sanayi ve Hizmet İstatistikleri**: Türkiye'deki firmaların üretim, istihdam, yatırım ve yenilikçilik faaliyetlerini ölçen bu araştırmalar, firma düzeyinde iktisadi analizler için değerli mikro veriler sağlar. Özellikle iktisadi büyüme, verimlilik analizleri ve sanayi dinamikleri üzerine yapılan çalışmalarda sıkça kullanılır.

Bu verilere ve TÜİK tarafından derlenen diğer veri tabanlarına  ilişkin daha fazla bilgi için bkz. <https://www.tuik.gov.tr/Kurumsal/Mikro_Veri>. 

## Veri Türleri  

Veriler araştırma türüne göre deneysel veya gözlemsel olabilir.  Verilerin toplanma biçimine ve zamanın nasıl ele alındığına göre de sınıflandırılabilir. 

### Deneysel Veriler 

Deneysel veriler, araştırmacının bir veya daha fazla değişkeni kontrol ederek, bu değişkenlerin diğer değişkenler üzerindeki etkilerini gözlemlediği çalışmalardan elde edilir. Deneysel araştırmalarda temel amaç, belirli bir müdahalenin (örneğin yeni bir eğitim modelinin) bir hedef değişken ya da sonuç (örneğin sınav performansı) üzerindeki **nedensel etkisini** test etmektir.

Deney süreci kabaca aşağıdaki adımlardan oluşur: 

  1. Hipotez geliştirme: Araştırmacı, deney tasarımına teorik modellerden veya önceki bilimsel çalışmalardan hareketle oluşturulan bir hipotezle başlar. Bu hipotez, bir veya daha fazla bağımsız değişkenin (müdahale edilen faktör) hedef değişken (sonuç) üzerindeki etkilerine ilişkin sınanabilir bir önermedir. Örneğin, bir eğitimci yeni bir eğitim tekniğinin  ilköğretim düzeyindeki öğrencilerin akademik performansları üzerindeki etkisine ilişkin bir hipotez oluşturur. Bu hipotez yeni tekniğin etkisiz olduğunu söyleyebilir. 
  
  2. Grupların belirlenmesi: Araştırma katılımcıları (denekler), genellikle ilgili anakütleden rastgele olarak, **kontrol grubu** ve **deney grubu** olmak üzere ikiye ayrılır. Kontrol grubu, müdahaleye maruz kalmazken, deney grubu müdahaleyi alır. Anakütleden tesadüfi örnekleme ile çekildiği varsayımı altında kontrol ve deney grupları her açıdan birbirine benzer olacaktır. Böylece hedef değişkende meydana gelen değişimler müdahaleye (tedaviye) atfedilebilir ve nedensel etki ölçülebilir. 
  
  3. Müdahale (tedavi/manipülasyon): Tedavi ya da müdahaleden önce hedef değişken ölçümleri (örneğin öğrenci performansı) her iki grup için yapılır. Daha sonra deney grubuna müdahale edilir, yani araştırmacı bağımsız değişkeni değiştirir (örneğin, yeni bir eğitim yöntemi uygulamak). Kontrol grubu karşılaştırma amacıyla tedavi ya da müdahaleden etkilenmez. 
  
  4. Veri toplama: Müdahaleden sonra, hedef değişken üzerindeki etkiler ölçülür (örneğin, sınav sonuçları) ve her iki grup için kaydedilir. 
  
  5. Sonuçların analizi: Müdahalenin etkilerini değerlendirmek için istatistiksel analizler yapılır ve hipotez test edilir. Eğer gerçekten tedavinin bir etkisi varsa, kontrol ve deney grupları arasında anlamlı bir fark oluşacaktır. Eğitim örneğimizde katılımcıların diğer özelliklerinin sabit kaldığı varsayımı altında deney grubunda ortalama performanstaki bir artış yeni programın  etkisi olarak yorumlanabilir. 
  
Bu derste istatistiksel çıkarsama başlığı altında, iki grup arasında ortalamada fark olup olmadığını nasıl sınayacağımızı öğreneceğiz.  

### Gözlemsel Veriler 

Gözlemsel veriler, araştırmacının herhangi bir müdahalede bulunmadığı, doğal süreçlerin izlendiği verilerden oluşur. Gözlemsel verilerin deneysel verilerden en önemli farkı araştırmacının deney ve kontrol gruplarını rassal bir şekilde oluşturamamasıdır. Gözlemsel veriler genellikle anket çalışmaları ve idari kayıtlardan elde edilen verilerdir.  Bu tür araştırmalar, bazı özel durumlar dışında, nedensellik yerine değişkenler arasındaki ilişkileri incelemek için yapılır. 

Gözlemsel verilerle yapılan  çalışmalar, kontrol edilemeyen dış faktörlerin bulunabileceği ve bu nedenle nedensellikten ziyade korelasyonun ortaya çıkabileceği türden çalışmalardır. Örneğin gelir düzeyi ile eğitim seviyesi arasındaki ilişkiyi inceleyen bir araştırmacı, bireylerin eğitim düzeylerini değiştiremez; sadece mevcut veriler üzerinden gözlem yapar. 

Açıkça deney yapılmasa da, bazı kısıtlayıcı varsayımlar altında, gözlemsel veriler kullanılarak nedensel çıkarım yapılması mümkündür. Deney-benzeri veriler (quasi-experimental data) deney ve kontrol gruplarının kendiliğinden oluştuğu gözlemsel verilerdir. Örneğin, birbirine çok benzer iki şehirden biri belirli bir tarihte çok sayıda göç almış olsun. Göç alan şehir (deney grubu) göç almayan şehirle (kontrol grubu) karşılaştırılabilir; örneğin göçün istihdam ya da fiyatlar üzerindeki etkisi incelenebilir.  Rassal atama yapılmadığı için (göç kendiliğnden oluşuyor) bu tür verilerden nedensel çıkarım yapılabilmesi için bazı özel varsayımların yapıldığı ileri düzey ekonometrik tekniklere ihtiyaç duyulur.  



### Veri Organizasyonuna Göre 

Veriler ölçüm ve toplanma biçimine, ve zamanın niteliğine göre dört farklı başlık altında toplanabilir: 

  - **Yatay kesit veri** (Cross-sectional data): Belirli bir zaman diliminde, birden fazla birimden (birey, hanehalkı, firma, şehir, vb.) toplanan verileri ifade eder. Yatay kesit verilerin kaynağı çoğunlukla idari kayıtlar ya da bilimsel anketlerdir. Bu anketleri araştırmacı kendi tasarlayacağı gibi diğer kurum ve kuruluşlar tarafından da hazırlanabilir. Örneğin, TÜİK tarafından her yıl yapılan hanehalkı ve fert araştırmaları (HHBA, HIA, vb) bir anket sonucunda farklı kişilere ait yaş, gelir ve eğitim düzeyi gibi bilgiler içerir. Gelir İdaresi Başkanlığı tarafından belirli bir yılda vergi mükelleflerinin bilanço ve gelir tablosu gibi finansal raporlarından oluşturulan idari kayıtlar da yatay kesit veri kümesi oluşturur. 

  - **Zaman serisi** (Time series data): Aynı birimden,  birbirini düzenli biçimde takip eden belirli zaman dilimlerinde alınan verileri ifade eder. Doğal olarak verilerin bir zaman sırası (kronoloji) vardır ve bu değiştirilemez. Örneğin, bir ülkenin yıllık GSYİH değerleri, aylık enflasyon oranları, bir finansal varlığın günlük değerleri ve getirileri zaman serisi verisidir. Bu veri türü özellikle finans ve makroiktisat alanlarında geliştirilen teori ve hipotezlerin değerlendirilmesinde, geleceğe dönük öngörü yapılmasında, zaman içerisindeki eğilimlerin ve dalgalanmaların analizinde kullanılır.
  
  - **Birleştirilmiş yatay kesit**  (Pooled cross-sectional data): Farklı zaman dilimlerinde toplanmış yatay kesit verilerinin birleştirilmesiyle oluşturulan veri kümesidir. İki boyutludur; hem zaman hem de yatay kesite ilişkin bilgi içerir ancak yatay kesit birimleri takip edilmez. Bu tür veriler, farklı dönemlerdeki birimlerin özelliklerini inceleme imkanı sunar. Örneğin, TÜİK hanehalkı bütçe anketleri her yıl ilgili anakütleden rassal örnekleme yöntemiyle farklı birimlerden veri toplar. Bu farklı hanelerden oluşan yatay kesit verileri bir araya getirerek birleştirilmiş yatay kesit veri kümesi elde edebiliriz. Böylece hanehalkı tüketiminin zaman içindeki eğilimini inceleyebiliriz. 
  
  - **Panel veri** (Panel or longitudinal data): **Aynı birim**lerin belirli zaman dilimlerinde gözlemlenmesiyle oluşturulan veri kümesidir. Örneğin, belirli bir grup bireyin yıllık gelir düzeyleri üzerinde yapılan bir araştırma panel veri olarak kabul edilir. Bir sektördeki firmaların zaman içindeki yatırım kararları ve buna ilişkin değişkenler bir panel veri kümesi oluşturur. Bu tür iki boyutlu veri, hem zaman içindeki değişimleri hem de  birimler arası ilişkileri analiz etme olanağı sağlar.
  
  
::: {#exm-panel1}

Panel veriye bir örnek olarak ülkelerarası  `Gapminder` verisi gösterilebilir. Bu veri kümesinde, ülkelerin 5 yıllık dönemlerdeki yaşam beklentisi, nüfus, kişi başına düşen gayri safi yurt içi hasıla (GSYİH) gibi değişkenler yer alır. Bu verilerle ülkelerin yıllar boyunca gelişimini izlemek mümkündür. 

```{r}
# install.packages("gapminder") # önceden yüklenmeli
library(gapminder)
head(gapminder)
```

Yukarıda bu veri kümesinin ilk 6 satırı yazdırılmıştır. Zaman boyutu *year*, birim boyutu *country* ile temsil edilmiştir. Ülkelerin her 5 yıllık dönem için bir gözlemi vardır (her değişken için). Birleşik veri yapısından görüldüğü gibi hem zaman hem de yatay kesit boyutunu bir arada içerir. Böylece hem zaman içindeki değişimi hem de birimler arasındaki ilişkileri inceleyebiliriz. 

```{r}
#| label: fig-gapminder1
#| fig-cap: "Bir panel veri örneği: Avrupa Ülkelerinde Kişi Başına Düşen GSYİH (1952-2007) (kaynak: Gapminder)" 
#| echo: false
#| 
# Avrupa Ülkelerinde Kişi Başına Düşen GSYİH (1952-2007)
# Avrupa ülkelerini filtreleyelim
europe_data <- subset(gapminder, continent == "Europe")

# Grafik için bir çerçeve oluşturalım
plot(europe_data$year, europe_data$gdpPercap, type = "n", xlab = "Yıl", ylab = "Kişi Başına GSYİH",
     main = "", ylim = range(europe_data$gdpPercap))

# Diğer ülkeleri gri çizgilerle gösterelim
countries <- unique(europe_data$country)
for (i in 1:length(countries)) {
  country_data <- subset(europe_data, country == countries[i])
  lines(country_data$year, country_data$gdpPercap, col = "lightgray", lwd = 1)
}

# Türkiye'yi siyah çizgi ile gösterelim
turkey_data <- subset(europe_data, country == "Turkey")
lines(turkey_data$year, turkey_data$gdpPercap, col = "black", lwd = 2)

# Türkiye'yi etiketleyelim
text(2000, max(turkey_data$gdpPercap), labels = "Turkey", pos = 4, col = "black")

```
@fig-gapminder1 Gapminder panel veri kümesinde yer alan Avrupa ülkelerinin kişi başına GSYİH grafiğini göstermektedir. Panel veri bize zamansal değişimleri ve birimlerin arasındaki ilişkileri  gözlemleme fırsatı sunar. @fig-gapminder1 tüm ülkeleri arkaplanda gösterirken, sadece Türkiye'yi öne çıkarıyor. Böylece, Türkiye'yi diğer Avrupa ülkelerinin kişi başına düşen GSYİH verileri arasında açık bir şekilde görebiliyoruz. 
::: 


## Nicel Değişkenler

Betimsel analizde karşılaşılan değişkenler farklı özelliklere ve ölçüm düzeylerine sahip olabilir. Değişkenleri genel olarak nicel (kantitatif) ve nitel (kalitatif) olmak üzere ikiye ayırabiliriz. Nicel değişkenler kendi içinde aralık değişkenleri ve oransal değişkenler olmak üzere ikiye ayrılır. 

### Aralık Ölçeği

Aralık (*interval*) değişkenleri, ölçülen değerler arasındaki "aralığın" veya "farkın" anlamlı olduğu değişkenlerdir. Bu tür değişkenler, sıralı bir şekilde düzenlenebilir ve aralarındaki farklar sabit ve anlamlıdır. 

Aralık değişkenlerinin en önemli özelliklerinden biri, sıfır noktasının keyfi veya anlamsız olmasıdır. Yani, sıfır değeri mutlak bir sıfırı (yokluk, hiçlik) temsil etmez. Örneğin, sıcaklık ölçümleri (Celsius veya Fahrenheit) bir aralık değişkenidir; burada sıfır derece sıcaklığın yokluğunu ifade etmez.

Aralık değişkenleri üzerinde toplama ve çıkarma işlemleri anlamlıdır, ancak çarpma ve bölme işlemleri genellikle anlamlı değildir. Bu, sıfır noktasının keyfi olmasından kaynaklanır.

1950-2023 döneminde bazı illerdeki ortalama sıcaklar şöyledir: 
```{r}
# Bazı illerin yıllık ortalama sıcaklıkları, Celsius derece
# 1950-2023 dönem ortalaması
tempC <- data.frame(il = c("İstanbul", "Ankara", "İzmir", "Ardahan"), 
                    ort_sicaklik = c(15.3, 12, 18, 3.7))
tempC
```

Yıllık sıcaklık ortalamalarına göre bu dört bölge arasında en sıcak il İzmir, en soğuk il ise Ardahan'dır. Ancak buradan hareketle İzmir'in Ardahan'dan yaklaşık 5 kat daha sıcak olduğunu söyleyemeyiz. 

Sıfır noktasının keyfiliğini görmenin bir yolu Celsius-Fahrenheit dönüştürmesi yapmaktır. Sıcaklık $X$ $^{\circ}C$ ise Fahrenheit cinsinden sıcaklık 
$$
Y = 1.8X+32
$$
olur. Buna göre santigrat cinsinden 0 noktası Fahrenheit cinsinden 32 $^{\circ}F$ dereceye karşılık gelir. Bu yeni değişkeni ekleyelim: 

```{r}
tempC$Fahrenheit <- 1.8*tempC$ort_sicaklik + 32
tempC
```

Suyun donma noktası keyfi olarak tanımlandığı için değerlerin birbirlerine oranları alınmaz. Aralıklar anlamlı bir biçimde yorumlanabilir. Her iki sıcaklık derecesi cinsinden 0 noktasının sıcaklığın olmadığı anlamına gelmediğine dikkat ediniz. 



### Oransal Ölçek

Oransal (ratio) değişkenler, hem aralıkların hem de oranların anlamlı olduğu nicel değişkenlerdir. Oransal ölçekli değişkenler anlamlı bir şekilde sıralanabilir, aralarındaki farklar ve oranlar yorumlanabilir. Oransal değişkenlerin en belirgin özelliği, mutlak sıfır noktasına sahip olmalarıdır. Bu, sıfır değerinin tam bir yokluk veya var olmama durumunu ifade ettiği anlamına gelir. Örneğin, ağırlık ve uzunluk ölçümleri oransal değişkenlere örnektir; sıfır ağırlık ya da sıfır uzunluk, hiçbir şeyin olmadığını gösterir.

Oransal değişkenler üzerinde tüm aritmetik işlemler (toplama, çıkarma, çarpma, bölme) anlamlıdır. Bu özellik, bu tür değişkenlerin analizinde daha geniş bir esneklik sağlar. İktisat, işletme, finans, ve sosyal bilim alanlarındaki bir çok değişken bu sınıfa girer. Örneğin hanelerin aylık gelir ve harcamaları oransal değişkenlerdir. 

```{r}
#| echo: false

hane_gelir_harcama <- head(hane_ornek[,c("hane_no","aylik_gelir", "aylik_harcama")])
# hane_gelir_harcama$oran <-  hane_gelir_harcama$aylik_harcama/hane_gelir_harcama$aylik_gelir
hane_gelir_harcama
```
Buna göre ilk hane aylık ortalama gelirinin yaklaşık %58'ini harcamaktadır. 3699 nolu hane ise gelirinden daha fazlasını harcamaktadır (yaklaşık %27 daha fazla). Her iki değişken için 0 değeri mutlak yokluğu ifade etmektedir. Ancak veri kümesinde bazı gözlemlerde tam olarak 0 değerini almaları gerekmez. Bu örneklemde aylık ortalama gelir ve harcaması 0 olan bir hane yoktur. 


## Nitel Değişkenler

Nitel (kalitatif) değişkenler nominal ve ordinal olmak üzere iki gruba ayrılır. 

### Nominal ölçek 

Nominal değişkenler, sıralama veya hiyerarşi içermeyen kategorik değişkenlerdir. Bu değişken türü, etiketler veya isimler kullanarak verileri kategorize eder. Örneğin, cinsiyet, kan grubu, medeni durum gibi değişkenler nominal ölçeklidir.

Hanehalkı harcama örnekleminde tasarruf değişkeni bu gruba girer: 
```{r}
head(hane_ornek[,c("hane_no", "aylik_gelir", "aylik_harcama", "tasarruf")])
```
Bu örneklemde tasarruf değişkeni iki karakterden oluşan değerler alır: hane tasarruf yapıyorsa "Evet", yapmıyorsa "Hayır".  
```{r}
table(hane_ornek$tasarruf)
```
Buna göre 520 hane tasarruf yapabiliyorken 1480 hane tasarruf yapmamaktadır. 

Veri kümelerinde bazı durumlarda nominal (kategorik) değişkenlere sayısal değerler atanabilir. Bu durum, özellikle veri analizi ve modelleme süreçlerinde dikkat edilmesi gereken önemli bir konudur. Nominal değişkenlerin sayısal değerler alması, yanlış analiz sonuçlarına yol açabilir. Bu nedenle, aşağıdaki noktalara dikkat edilmelidir:

- Nominal Değişkenlerin Tanımı: Nominal değişkenler, belirli kategorilere ayrılmış veriler olup, bu kategoriler arasında herhangi bir sıralama veya sayısal ilişki yoktur. Örneğin: cinsiyet (Erkek = 1, Kadın = 2) veya renk (Kırmızı = 1, Mavi = 2, Yeşil = 3).

- Sayısal Değerlerin Yanlış Yorumu: Nominal değişkenlere atanan sayısal değerler, sayısal işlemler için kullanılmamalıdır. Örneğin, "Erkek" ve "Kadın" için 1 ve 2 sayılarının atanması, bu sayıların arasında bir büyüklük veya sıralama ilişkisi olduğu anlamına gelmez.

- Kategorik Verileri Kodlama: Kategorik verilerin sayısal modellere dahil edilmesi gerektiğinde, genellikle ikili (binary) temsil ("one-hot encoding", "dummy variable") gibi yöntemler kullanılır. Bu yöntemler, her kategoriyi ayrı bir ikili (0/1) değişken olarak temsil eder.

Örneğin hanehalkı veri kümesinde `sigara` değişkeni hanede sigara içen olup olmadığına ilişkin bilgi vermektedir: 
```{r}
hane_sigara <- head(hane_ornek[,c("hane_no", "sigara")])
hane_sigara
```
Bu değişken hanede sigara içen biri varsa 1, yoksa 2 değerini alan nominal bir değişkendir. `Sigara`'yı ikili (0/1) değişken biçiminde yeniden kodlayabiliriz: 
```{r}
# "sigara" sütununu kategorik değişken olarak tanımlama
hane_sigara$sigara_faktor <- factor(hane_sigara$sigara, 
                                    levels = c(1, 2), 
                                    labels = c("Evet", "Hayır")
                                    )
# kukla değişken olarak tanımla 
sigara_kukla <- model.matrix(~ sigara_faktor - 1, data = hane_sigara)
cbind(hane_sigara, sigara_kukla)
```
`sigara_faktorEvet` sigara içenlerin olduğu bir hanede 1, diğerlerinde 0 değerini almaktadır. `sigara_faktorHayır` ise sigara içilmeyen hanelerde 1, diğerlerinde ise 0 değerini almaktadır. 


### Ordinal ölçek 

Ordinal değişkenler, sıralama veya derecelendirme içeren kategorik değişkenlerdir. Bu tür değişkenlerde, kategoriler arasında bir sıra veya hiyerarşi vardır. Ordinal değişkenler, sıralanabilir kategoriler içerir. Kategoriler arasındaki farklar sabit veya standart değildir. Örnek olarak, eğitim seviyesi, memnuniyet dereceleri, ürün kalite dereceleri verilebilir.

Örneğin `memnuniyet` bir ürünün değerlendirmesine ilişkin 6 gözlem içeren bir faktör değişkenidir: 
```{r}
memnuniyet <- factor(c("Düşük", "Orta", "Yüksek", "Orta", "Orta", "Yüksek"), 
                     order = TRUE, 
                     levels = c("Düşük", "Orta", "Yüksek"))
memnuniyet
```

Hane verilerinde yer alan `saglik_merkezi_erisim` ve `zor_egitim_erisim` değişkenleri sıralı kategorik değişkenlerdir: 
```{r}
veri <- hane_ornek[1:10,c("saglik_merkezi_erisim", "saglik_merkezi_erisim_olcek")]
veri
```
Hanenin bulunduğu yerden sağlık merkezlerine erişimin kolaylığına ilişkin bilgi içeren bu değişken 5 seviyeden oluşur. Bu seviyeler 1-5 arasında sayısal değerlerle ifade edilmiştir. Buna göre 1 (Çok kolay), 2 (Kolay), 3 (Orta), 4 (Zor) ve 5 (Çok zor). `saglik_merkezi_erisim_olcek` bu bilgileri karakter formatında içerir. İstenirse bu değişken faktör değişkeni olarak da tanımlanabilir.  


## Merkezi Eğilim Ölçüleri {#betimsel-merkezi}

Betimsel analizde, bir veri kümesinin genel eğilimini ya da merkezini özetleyen bazı temel ölçülere ihtiyaç duyarız. Bu ölçüler, veri kümesindeki değerlerin nerede toplandığını gösterir ve bize verinin genel yapısı hakkında bilgi verir. Merkezi eğilim ölçüleri, veri dağılımının tipik ya da ortalama bir değerini temsil etmeye çalışır. İstatistikte en yaygın kullanılan merkezi eğilim ölçüleri ortalama, medyan ve moddur.


### Ortalama 

Ortalama, genellikle bir veri kümesinin merkezini ya da "tipik" değerini gösteren en yaygın kullanılan ölçüdür. Gündelik hayatta da sıklıkla kullanılan bu kavram aslında iki farklı şekilde karşımıza çıkar: **anakütle ortalaması** ve **örneklem ortalaması**. Bu iki kavram birbirine benzer görünse de, aralarındaki farkları anlamak istatistiksel analizlerde oldukça önemlidir.

::: {#def-popmean}

## Anakütle ortalaması, $\mu$

$N$ elemanlı bir anakütleye ilişkin verilerin anakütle ortalaması, bu değerlerin toplamınının gözlem sayısına bölünmesiyle bulunur: 
$$
\mu  =\frac{1}{N}\sum_{i=1}^N x_i
$$ {#eq-merkez1}
:::  

Anakütle ortalaması, $\mu$, bir araştırmanın hedefi olan **tüm birimlerden** oluşan veri kümesinin ortalamasıdır. Örneğin, bir şehirde yaşayan tüm insanların ortalama geliri veya bir fabrikanın ürettiği tüm ürünlerin ortalama ağırlığı anakütle ortalamasını temsil eder. Anakütle ortalaması, teorik olarak tüm birimleri kapsayan bir hesaplamadır ve genellikle pratikte tam olarak gözlemlenemeyebilir.

::: {#exm-merkez0}
`hane_anakutle.RData` tüm hanehalklarına ilişkin bilgi içeren bir veri kümesi olsun. `R`'ın `mean()` fonksiyonunu kullanarak bu anakütlede ortalama hane büyüklüğünü, ortalama aylık geliri ve ortalama aylık harcamayı hesaplayalım: 
```{r}
load("Data/hane_anakutle.RData")
# anakütle hacmi
N <- nrow(hane_anakutle)
ort_kisi <- mean(hane_anakutle$hane_kisi_sayisi)
ort_gelir <- mean(hane_anakutle$aylik_gelir)
ort_harcama <- mean(hane_anakutle$aylik_harcama)
anakutle_ort <- cbind(N, ort_kisi, ort_gelir, ort_harcama)
print(anakutle_ort)
```
Anakütlede ortalama hane büyüklüğü yaklaşık 3.5 kişi, ortalama aylık gelir yaklaşık 3532 TL, ve ortalama aylık harcama yaklaşık 3198 TL'dir. 
:::

::: {#def-samplemean}

## Örneklem ortalaması, $\bar{x}$

Eğer elimizde bir anakütleden çekilmiş $n$ boyutlu bir örneklem varsa bu durumda örneklem ortalaması 
$$
\bar{x}  =\frac{1}{n}\sum_{i=1}^n x_i
$$ {#eq-merkez2}
olarak tanımlanır. 
:::  

Bu tanımlar matematiksel olarak eşdeğer olsalar da yorumlarının farklı olduğuna dikkat ediniz. Örneklem ortalaması, anakütle yerine, anakütleyi temsil eden daha küçük bir alt küme olan örneklemden hesaplanan ortalamadır. Örneğin, bir şehirde yaşayan 1000 kişilik bir örneklem seçildiğinde, bu kişilerin ortalama geliri örneklem ortalaması olarak adlandırılır. Başka bir örneklem çekildiğinde $\bar{x}$ da değişir, yani sabit değildir (rassal değişken).  İlerleyen bölümlerde örneklem ortalaması ile anakütle ortalamasına ilişkin nasıl çıkarım yapıldığını öğreneceğiz.  


::: {#exm-merkez1}
Anakütleden 10 öğrenci rassal olarak seçilmiş ve GPA değerleri kaydedilmiştir: 3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9. 

```{r}
gpa <- c(3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9)
mean(gpa)
```
Notların örneklem ortalaması 2.94 olarak bulunmuştur. Bu değer anakütlenin merkezine ilişkin çıkarımlar yapmak amacıyla kullanılabilir. 
:::

Örneklem ortalaması tüm gözlem değerlerine eşit ağırlık ($1/n$) verir: 
$$
\bar{x}  =\frac{1}{n}\sum_{i=1}^n x_i = \frac{1}{n}x_1+\frac{1}{n}x_2+\ldots+\frac{1}{n}x_n.
$$

Verilerde çok büyük ya da çok küçük değerler varsa ortalama bu değerlere duyarlı olur (bkz. @fig-ortalama1). 

```{r}
#| label: fig-ortalama1
#| fig-cap: "Merkezi eğilim: Ortalama"
#| fig-subcap: 
#|   - "Ortalama (0 hariç) "
#|   - "Ortalama (0 dahil)" 
#| layout-ncol: 2
#| fig-width: 4
#| fig-height: 3
#| warning: false
#| echo: false
#| 
notlar1 <- c(55,65,75,75,70,85,80,80,60,70)
ort1 <- mean(notlar1)
notlar2 <- c(55,65,75,75,70,85,80,80,60,70,0)
ort2 <- mean(notlar2)

par(bty = "n")
stripchart(notlar1, method = "stack", xaxt='n',
           pch = 19, at = 0, xlim = c(0,100), cex.axis=0.8,
           col = "black", xlab = "Not")
axis(1, at = seq(0, 100, by = 5))
abline(v = ort1, col = "black", lty = 2)
text(ort1-15, 1.3, paste("ortalama =\n", round(ort1, 2)), pos = 1)

par(bty = "n")
stripchart(notlar2, method = "stack", xaxt='n',
           pch = 19, at = 0, xlim = c(0,100),
           col = "black", xlab = "Not")
axis(1, at = seq(0, 100, by = 5))
abline(v = ort2, col = "black", lty = 2)
text(ort2-15, 1.3, paste("ortalama =\n", round(ort2, 2)), pos = 1)
```

@fig-ortalama1-1, notu 0 olan gözlem hariç tutulduğunda ortalamanın 71.5 olduğunu göstermektedir. Bu durumda, öğrencilerin çoğunluğunun aldığı puanlar 60-80 aralığındadır ve ortalama bu merkezi yansıtmaktadır. @fig-ortalama1-2 ise 0 puanının dahil edildiği durumu göstermektdir. Bu durumda uç değer ortalamayı aşağıya çekmiştir ve 65 olmuştur. Görüldüğü gibi sadece bir adet uç değer (0 puanı) bile ortalamanın ciddi şekilde düşmesine neden olmuştur.


::: {#exm-merkez2}

Hane anakütlesinden 200 gözlemlik bir rassal örneklem çekelim ve örneklem ortalamalarını hesaplayalım: 

```{r}
set.seed(468) # replikasyon için 
ind <- sample(1:N, # 1,2,...,N tamsayı vektörü
              size = 200, # çekilecek örneklem büyüklüğü
              replace = FALSE # yerine koymadan çek
              )
head(ind)
```
`sample()` fonksiyonunu kullanarak 1-10000 arasındaki tamsayı kümesinden tesadüfi olarak 200 tanesini yerine koymadan çektik ve `ind` nümerik (tamsayı) vektörünü oluşturduk. Daha sonra bu gözlemlere karşılık gelen satırları seçerek örneğimizi oluşturacağız: 
```{r}
ornek1 <- hane_anakutle[ind,]
head(ornek1[,1:5])
``` 
Örneklem ortalamalarını hesaplayalım: 
```{r}
n <- nrow(ornek1)
ort_kisi <- mean(ornek1$hane_kisi_sayisi)
ort_gelir <- mean(ornek1$aylik_gelir)
ort_harcama <- mean(ornek1$aylik_harcama)
orneklem_ort <- cbind(n, ort_kisi, ort_gelir, ort_harcama)
print(orneklem_ort)
```
200 haneden oluşan bu rassal örneklemdeki ortalama hane büyüklüğü 3.59, ortalama aylık gelir yaklaşık 3669 TL, ve ortalama aylık harcama yaklaşık 3333 TL'dir. 
:::


### Medyan 

Medyan, veriler küçükten büyüğe sıralandığında tam ortada yer alan değerdir. Eğer veri setinde çift sayıda gözlem varsa, ortadaki iki değerin ortalaması alınır.

::: {#exm-medyan1}
GPA verisi için medyanı hesaplayalım. Burada gözlem sayısı $n=10$ olduğu için sıralanmış verilerde $n/2$ ile $n/2 +1$ pozisyonundaki değerlerin ortalamasıdır: 
```{r}
gpa <- c(3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9)
rbind(`sıra_no`=1:10, `sıralanmış_gpa`=sort(gpa))
```
5 ve 6 pozisyonundaki değerlerin ortalaması $(2.9+3.1)/2=3$ medyanı verir. R programında `median()` fonksiyonu ile: 
```{r}
median(gpa)
```
bulunabilir. 

Gözlem sayısı, $n$, tek sayı olduğunda sıralanmış veride tam ortadaki değer medyanı verir. Veri kümesine bir gözlem daha ekleyelim ve medyanı hesaplayalım.  
```{r}
gpa2 <- c(3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9, 2.6)
rbind(`sıra` = 1:11, `sıralı_gpa`=sort(gpa2))
```
$n=11$ olduğuna göre $(n+1)/2=6$ pozisyonundaki değer medyandır. Buna göre medyan 2.9 olur. 
```{r}
median(gpa2)
```
:::

Medyan ortalamaya kıyasla uç değerlere daha az duyarlıdır (bkz. @fig-medyan1). 
```{r}
#| label: fig-medyan1
#| fig-cap: "Merkezi eğilim: Medyan"
#| fig-subcap: 
#|   - "Medyan (sıfırlar hariç) "
#|   - "Medyan (sıfırlar dahil)" 
#| layout-ncol: 2
#| fig-width: 4
#| fig-height: 3
#| warning: false
#| echo: false
#| 
notlar1 <- c(55,65,75,75,70,85,80,80,60,70)
med1 <- median(notlar1)
ort1 <- mean(notlar1)
notlar2 <- c(55,65,75,75,70,85,80,80,60,70,0,0,0)
med2 <- median(notlar2)
ort2 <- mean(notlar2)

par(bty = "n")
stripchart(notlar1, method = "stack", xaxt='n',
           pch = 19, at = 0, xlim = c(0,100), cex.axis=0.8,
           col = "black", xlab = "Not")
axis(1, at = seq(0, 100, by = 5))
abline(v = med1, col = "black", lty = 2)
# points(mean(notlar1), 0, col = "red", pch = 19)
abline(v = ort1, col = "red", lty = 2)
text(ort1-15, 1.3, paste("Ortalama =\n", round(ort1, 2)), pos = 1)
text(med1, 1.0, paste("Medyan =\n", round(med1, 2)), pos = 4)

par(bty = "n")
stripchart(notlar2, method = "stack", xaxt='n',
           pch = 19, at = 0, xlim = c(0,100),
           col = "black", xlab = "Not")
axis(1, at = seq(0, 100, by = 5))
abline(v = med2, col = "black", lty = 2)
abline(v = ort2, col = "red", lty = 2)
text(ort2-15, 1.3, paste("Ortalama =\n", round(ort2, 2)), pos = 1)
text(med2+1, 1.0, paste("Medyan =\n", round(med2, 2)), pos = 4)
```

@fig-medyan1-1 öğrencilerin bir dersten aldıkları notların nokta grafiğini (her nokta bir öğrenciyi temsil etmektedir) ve merkeze ilişkin ölçüleri göstermektedir.  Bu verilerde medyan 72.5 olarak hesaplanmıştır. Ortalamanın ise 71.5 olduğunu görüyoruz. Medyanın ve ortalamanın birbirine oldukça yakın olduğunu ve merkezi iyi yansıttılarını söyleyebiliriz. 

@fig-medyan1-2 ise 0 değerini alan üç gözlemin dahil edildiği grafiği göstermektedir. Ortalamanın ciddi şekilde düşerek 55 olduğunu, medyanın ise 70'e gerilediğini görüyoruz. Burada ilginç olan nokta, uç değerlerin ortalamayı büyük ölçüde düşürmesine rağmen medyanın daha stabil kalmasıdır. Medyan, uç değerlere karşı daha dirençlidir çünkü veri setinin ortadaki değerine bakar, aşırı küçük veya aşırı büyük değerlerden etkilenmez.


::: {#exm-medyan2}

Hanehalkı anakütlesi ve örneklemde hane kişi sayısı, aylık gelir ve aylık harcama için medyanları hesaplayalım. 
```{r}
med_kisi <- median(hane_anakutle$hane_kisi_sayisi)
med_gelir <- median(hane_anakutle$aylik_gelir)
med_harcama <- median(hane_anakutle$aylik_harcama)
anakutle_medyan <- cbind(med_kisi, med_gelir, med_harcama)
anakutle_medyan
```

```{r}
med_kisi <- median(ornek1$hane_kisi_sayisi)
med_gelir <- median(ornek1$aylik_gelir)
med_harcama <- median(ornek1$aylik_harcama)
ornek_medyan <- cbind(med_kisi, med_gelir, med_harcama)
ornek_medyan
```
Hem anakütlede hem de örneklemde medyan hane büyüklüğü 3 kişidir. Aylık gelir ve harcama değişkenlerinin örneklem medyanları anakütle medyanlarından biraz daha yüksektir. 
:::




### Mod (En sık değer)

Bir veri kümesinin modu en çok tekrar eden değer ya da değerler olarak tanımlanır. Verilerde mod olmayabilir ya da birden fazla olabilir. 

::: {#exm-mod1}
Aşağıdaki veri kümesinin modunu bulalım. R `table()` fonksiyonunu kullanarak her bir değerin kaç kere tekrar ettiğini görebiliriz: 
```{r}
v1 <- c(7, 2, 7, 3, 7, 1, 3, 4, 7, 3, 2, 2, 4, 8, 5, 6, 7, 9, 1)*10
table(v1)
```
Sıklık değerlerini küçükten büyüğe doğru sıralayalım: 
```{r}
sort(table(v1))
```

Buna göre mod veri kümesinde 5 kere tekrar eden 70 değeridir (bkz. @fig-mod1). 

```{r}
#| label: fig-mod1
#| fig-cap: "Mod: en sık tekrarlayan değer" 
#| warning: false
#| echo: false
#| 
v1 <- c(7, 2, 7, 3, 7, 1, 3, 4, 7, 3, 2, 2, 4, 8, 5, 6, 7, 9, 1)*10
ort1 = mean(v1)
medyan1 <- median(v1)
mod1 <- 70
# tekrar sayılarını üzerinde göster
table1 <- table(v1)

par(bty = "n")
stripchart(v1, method = "stack", xaxt='n',
           pch = 1, cex = 1.5, at = 0, xlim = c(0,100), 
           col = "black", xlab = "X")
axis(1, at = seq(0, 100, by = 10))
text(mod1, 0.5, paste("mod =", round(mod1, 2)), pos = 3)
for (i in seq_along(table1)) {
  value <- as.numeric(names(table1)[i])
  count <- table1[i]
  text(value, 0.08, count, labels = count, pos=4)
}
```
:::  

`R`da en sık değeri hesaplayan bir komut yoktur. Kendi fonksiyonumuzu yazıp kullanabiliriz. 

::: {#exm-modfonks}
Girdi olarak bir nümerik ya da faktör değişkenini alıp modu hesaplayan bir `R` fonksiyonu yazınız. 

**Çözüm:**

```{r}
# x vektörünün modunu hesaplayan fonksiyon
mod <- function(x) {
  # Faktör değişkenleri karakter dizilerine dönüştür
  if (is.factor(x)) {
    x <- as.character(x)
  }
  # sıklık tablosu oluştur
  tablo <- table(x)
  max_freq <- max(tablo)
  modes <- names(tablo)[which(tablo == max_freq)]
  
  # Eğer x numerikse, sonucu numerik yap
  if (is.numeric(x)) {
    return(as.numeric(modes))
  }
  
  # Değilse, karakter olarak döndür
  return(modes)
}
```

Önceki örnekteki veri kümesine uygulayalım: 
```{r}
mod(v1)
```
:::  

::: {#exm-mod1coklu}
Bir değişkenin birden fazla modu olabilir. Örneğin aşağıdaki veri kümesinde 
```{r}
v2 <- c(3, 2, 5, 3, 7, 2, 3, 4, 5, 3, 3, 2, 4, 5, 5, 6, 7, 8, 5)*10
table(v2)
```
30 ve 50 değerleri beşer kere tekrar etmiştir. 
```{r}
mod(v2)
```
:::


::: {#exm-mod2}
Hane örnekleminde sağlık merkezlerine erişimin zorluğuna ilişkin bilgi içeren `saglik_merkezi_erisim` değişkeninin modunu hesaplayınız. 

Frekans tablosunu oluşturalım: 
```{r}
table(ornek1$saglik_merkezi_erisim)
```
Buna göre en sık gözlenen değer 2'dir (Kolay). 
```{r}
table(ornek1$saglik_merkezi_erisim_olcek)
```
`saglik_merkezi_erisim_olcek` karakter değişkenini kullanarak bir faktör değişkeni oluşturalım: 
```{r}
# Faktör değişkeni tanımlama
ornek1$saglik_merkezi_erisim_faktor <- factor(
  ornek1$saglik_merkezi_erisim_olcek,
  levels = c("Çok kolay", "Kolay", "Orta", "Zor", "Çok zor"),
  ordered = TRUE
)

print(levels(ornek1$saglik_merkezi_erisim_faktor))
```
Bu faktör değişkeninin sıklık tablosunu oluşturalım. 
```{r}
table(ornek1$saglik_merkezi_erisim_faktor)
```
Bu tablodan da görüleceği gibi en sık cevap "Kolay"'dır (bkz. @fig-mod2). 
```{r} 
#| label: fig-mod2
#| fig-cap: "En sık değer: sağlık merkezine erişimin kolaylığı" 
#| warning: false
#| echo: false
#| 
value_counts <- table(ornek1$saglik_merkezi_erisim_faktor) 
df <- as.data.frame(value_counts)
colnames(df) <- c("Value", "Frequency")
plot(as.numeric(df$Value), 
     df$Frequency, pch = 16, ylim = c(0,120),
     xlab = "Sağlık merkezine erişim", 
     ylab = "Frekans", xaxt = 'n')

# Add x-axis labels as the factor levels
axis(1, at = 1:length(df$Value), labels = levels(df$Value))

# Add text labels for the frequencies
text(as.numeric(df$Value), 
     df$Frequency, labels = df$Frequency, pos = 3, col = "red")
```

Yazdığımız fonksiyonu kullanarak da modu bulabiliriz:  
```{r}
mod(ornek1$saglik_merkezi_erisim)
mod(ornek1$saglik_merkezi_erisim_olcek)
```
:::

Sıralı nominal (ordinal) değişkenler için mod ve medyan genellikle anlamlı bir bilgi içerir. Yukarıdaki sonuçlardan hareketle hanenin bulunduğu yerden sağlık merkezine erişimin zorluğuna ilişkin en çok verilen cevap "Kolay"'dır. Ancak nominal ve ordinal değişkenlerin nümerik temsilleri üzerinden ortalamaları yorumlarken dikkatli olmak gerekir. Özellikle sıralama aralıklarının eşit olmadığı durumlarda ortalamanın yanı sıra medyan ve modun kullanılması tercih edilebilir.  


::: {#exm-mod3}
Eğitim düzeyine ilişkin 6 gözlemli bir karakter vektörü verilmiş olsun: 
```{r}
diploma <- c("İlkokul", "Lise", "Üniversite", "Lise", "Lise", "Üniversite")
```

`diploma` karakter vektöründen hareketle bir faktör değişkeni oluşturalım: 
```{r}
egitim_seviyesi <- factor(diploma,
                          levels = c("İlkokul", "Lise", "Üniversite"),
                          ordered = TRUE)
```
`egitim_seviyesi` en son kazanılan diploma bilgisini içeren bir faktör değişkenidir: 
```{r}
egitim_seviyesi
```

Faktör değişkeni sayısal değere dönüştürüldüğünde eğitim düzeyinin sırasını yansıtacak şekilde ilkokul için 1, lise için 2, üniversite için 3 değerini almaktadır. 

```{r}
as.numeric(egitim_seviyesi)
```
```{r}
ortalama_egitim <- mean(as.numeric(egitim_seviyesi))
print(ortalama_egitim)
```
```{r}
mod(egitim_seviyesi)
```

```{r}
median(as.numeric(egitim_seviyesi))
```

Ortadaki ve en sık rastlanan eğitim düzeyi "2" ya da "Lise"'dir. 
:::

### Geometrik ortalama 

Geometrik ortalama büyüme ve getiri oranları veya yüzdeleri hesaplamak için uygun bir ölçüdür. Aritmetik ortalamanın yanı sıra, özellikle büyüme oranlarının ortalamasını hesaplamada daha doğru sonuçlar verebilir. Geometrik ortalama gözlem değerlerinin çarpımının $n$-kökü olarak tanımlanır: 

$$
\bar{x}_g = \sqrt[n]{x_1\cdot x_2\cdot \ldots\cdot x_n}=\left(x_1\cdot x_2\cdot \ldots\cdot x_n \right)^{1/n}=\left( \prod_{i=1}^n x_i \right)^{1/n}
$$ {#eq-geometric1}
Bu formüldeki $\prod_{i=1}^n x_i$, 1'den $n$ kadar tüm değerlerin çarpımını gösteren çarpım işlemcisidir. 

Özellikle finansta getiri oranlarının geometrik ortalaması daha doğru bir şekilde ortalama davranışı yansıtabilir. $g_i$ getiri oranı ise, geometrik ortalama 
$$
\bar{x}_g = \left( \prod_{i=1}^n (1+g_i) \right)^{1/n} -1
$$ {#eq-geometric2}
olarak tanımlanır. 

::: {#exm-geometric1}

Bir yatırımcı 1000 TL'lik anaparayı bir finansal varlığa yatırmıştır. Varlığın değeri 1. yılda 1200 TL, 2. yılda 1260 TL, 3. yılda 1134 TL, 4. yılda 1304.1 TL, ve 5. yılda 1238.9 TL olmuştur. Yıllık ortalama getiri yüzde kaçtır? 

**Çözüm**: 

Önce her yılın getirisini hesaplayalım: 

1. yıl getirisi: 
$$
\frac{1200}{1000} - 1 = 0.20
$$

2. yıl getirisi: 
$$
\frac{1260}{1200} - 1 = 0.05
$$

3. yıl getirisi: 
$$
\frac{1134}{1260} - 1 = -0.10
$$

4. yıl getirisi: 
$$
\frac{1304.1}{1134} - 1 = 0.15
$$

5. yıl getirisi: 
$$
\frac{1238.9}{1304.1} - 1 = -0.05
$$
Aritmetik ortalamayı hesaplarsak
$$
\bar{x} = \frac{0.2+0.05-0.10+0.15-0.05}{5}=0.05
$$
buluruz. Yani aritmetik ortalamaya göre varlık her yıl ortalama $\%5$ büyümüştür. Ancak bu yanıltıcı olabilir. 

| Yıl | Değer   | Getiri  | Aritmetik Ortalama Getiri | Aritmetik Ortalama Değer | Geometrik Ortalama Getiri | Geometrik Ortalama Değer |
|-----|---------|---------|---------------------------|--------------------------|---------------------------|--------------------------|
| 1   | 1200    | %20     | %5                        | 1050                     | %4.378                     | 1043.8                   |
| 2   | 1260    | %5      | %5                        | 1102.5                     | %4.378                     | 1089.48                 |
| 3   | 1134    | -%10    | %5                        |1157.6                     | %4.378                     | 1137.2                  |
| 4   | 1304.1  | %15     | %5                        | 1215.5                  | %4.378                     | 1186.9                   |
| 5   | 1238.9  | -%5     | %5                        | 1276.28                  | %4.378                     | 1238.9                  |

: 1000 TL yatırımın yıllık getirileri ve dönem sonu değeri {#tbl-geometric1}

Şimdi geometrik ortalamayı hesaplayalım: 
$$
\text{Geometrik Ortalama} = \left( (1 + 0.20) \times (1 + 0.05) \times (1 - 0.10) \times (1 + 0.15) \times (1 - 0.05) \right)^{\frac{1}{5}} - 1
$$
$$
= \left( 1.20 \times 1.05 \times 0.90 \times 1.15 \times 0.95 \right)^{\frac{1}{5}} - 1= 1.2389^{\frac{1}{5}} - 1=1.0438 - 1 = 0.0438
$$
```{r}
# 
g <- c(1.2,1.05,0.9,1.15,0.95)
prod(g)^(1/5)-1
```

Buna göre finansal varlık yılda ortalama yaklaşık $\%4.38$ büyümüştür. Bu aritmetik ortalamaya göre daha düşük bir ortalama getiriye işaret etmektedir.  

@tbl-geometric1 yatırımın yıllara göre getirilerini ve dönem sonu değerini göstermektedir. Her yıl bu ortalama oranda büyürse 5 yıl sonundaki değere ulaşılmaktadır. Aritmetik ortalama ile hesapladığımızda ise daha büyük bir değere ulaşıyoruz.  

  
::: 


## Sıra İstatistikleri, Kantiller ve Yüzdelikler 

Veriyi betimlemedeki en önemli araçlardan biri gözlemlerin küçükten büyüğe doğru sıralanmasıdır. Elimizde $x_1,x_2,\ldots,x_n$ gibi bir örneklem olduğunu düşünelim. Bu değerleri artan şekilde sıralayalım: 
$$
x_{(1)}, x_{(2)},x_{(3)},\ldots,x_{(n)}
$$
Burada sıralamada $k$nci konumda yer alan değer, $x_{(k)}$, $k$ sıra istatistiğidir. Örneğin $x_{(1)}$ en küçük (minimum), $x_{(n)}$ en büyük (maximum) değeri gösterir. 
$$
x_{(1)} = \min(x_1,x_2,\ldots,x_n)
$$
$$
x_{(n)} = \max(x_1,x_2,\ldots,x_n)
$$

::: {#exm-sira1}

```{r}
gpa <- c(3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9)
rbind(`sıra` = 1:10, `sıralı_gpa` = sort(gpa))
```
Bu sıralı veri kümesinden hareketle 
$$
x_{(1)} = 1.8,~~ x_{(2)}=2.0,~~ x_{(3)}=2.50,\ldots,~~  x_{(10)}=3.9
$$ 
yazabiliriz. 
:::

Sıra istatistiklerini kullanarak gözlemlerin yüzde kaçının küçük olacağı değerleri bulabiliriz. Gözlemlerin yaklaşık olarak $\%(k/n)100$ kadarı $x_{(k)}$ değerinden küçük olacaktır. Bu istatistikler verinin değişkenliği ve yayılımı hakkında önemli bilgiler verebilir. 

::: {#def-kantil}

## Kantil 

Bir veri kümesini belirli sayıda eşit parçaya bölen değerlere kantil (quantile) adı verilir. Bu değerler, veri setindeki gözlemlerin belirli bir yüzdesinin altında veya üstünde kalan değerleri gösterir. Kantiller, sıra istatistikleri kullanılarak hesaplanır. 

Uygulamada genellikle gözlemleri ikiye, dörde, ona ya da yüze bölen kantil değerleri kullanılır.  
:::

<!-- Bir veri kümesinde $p$ yüzdelik kantil, gözlemlerin $p$ yüzdesinin bu değerin altında olduğunu gösterir:  -->
<!-- $$ -->
<!-- Q_p = x_{(\lceil np \rceil)} -->
<!-- $$ -->
<!-- Burada $n$ gözlem sayısıdır. Tavan fonksiyonu $\lceil \cdot \rceil$ bir sayıyı yukarı yuvarlar. -->
<!-- $$ -->
<!-- Q_p = (1 - d) \cdot x_{\lfloor np \rfloor} + d \cdot x_{\lfloor np \rfloor + 1} -->
<!-- $$ -->
<!-- Burada $n$ gözlem sayısını, $\lfloor \cdot \rfloor$ bir sayıyı aşağı yuvarlayan taban fonksiyonunu, $d = np - \lfloor np \rfloor$ olarak hesaplanan kesirli kısmı göstermektedir. -->
<!-- :::  -->

<!-- Örnek olarak sıralanmış GPA değerlerini düşünelim:  -->
<!-- ```{r} -->
<!-- gpa <- c(3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9, 2.7) -->
<!-- cbind(`sıra` = 1:11, `sıralı_gpa` = sort(gpa)) -->
<!-- ``` -->

<!-- $p=0.25$ olsun. Bu durumda  -->
<!-- $$ -->
<!-- x_{\lfloor np \rfloor}=x_{\lfloor 2.75 \rfloor}=x_{(2)}=2.0 -->
<!-- $$ -->
<!-- ve -->
<!-- $$ -->
<!-- x_{\lfloor np \rfloor + 1}=x_{(3)}=2.5 -->
<!-- $$ -->
<!-- olur. $d = np - \lfloor np \rfloor=2.75-2=0.75$ olduğundan  -->
<!-- $$ -->
<!-- Q_{0.25}= 0.25 \cdot 2.0 + 0.75 \cdot 2.5=2.375 -->
<!-- $$ -->


::: {#def-kartil}

## Kartil (Çeyreklik, Dördebölen, Quartile)
Çeyreklikler, kantillerin özel bir durumudur ve gözlemleri dört eşit parçaya böler:

- **Birinci Çeyrek ($Q_1$)**: Gözlemlerin %25'inin altında kaldığı değeri gösterir.
- **İkinci Çeyrek ($Q_2$) veya Medyan**: Gözlemlerin %50'sinin altında kaldığı değeri gösterir (medyan).
- **Üçüncü Çeyrek ($Q_3$)**: Gözlemlerin %75'inin altında kaldığı değeri gösterir.

Bu çeyrekler, veri setinin yayılımı ve merkezi eğilimi hakkında bilgi verir. Çeyrekler, sıra istatistikleri kullanılarak hesaplanır. 

Sıralanmış $n$ gözlemli bir örneklemde, $k = \frac{n+1}{4}=0.25(n+1)$ olmak üzere, $j$ kartili aşağıdaki formül ile bulunabilir: 

\begin{align*}
Q_j &= \begin{cases}
    x_{(jk)} & \text{ } jk \text{ bir tamsayı ise} \\
    x_{\lfloor jk \rfloor} + (jk - \lfloor jk \rfloor) \cdot (x_{\lfloor jk \rfloor + 1} - x_{\lfloor jk \rfloor}) & \text{  } jk \text{ bir tamsayı değilse}
    \end{cases} \\
\end{align*}


Burada $\lfloor \cdot \rfloor$ bir sayıyı aşağı yuvarlayan taban fonksiyonunudur; $a=1.85$ ise $\lfloor a \rfloor=1$ olur. Yani $a$'dan büyük olmayan en büyük tamsayı 1'dir. Benzer şekilde tavan fonksiyonu, $\lceil \cdot \rceil$, tanımlanabilir. Tavan fonksiyonu $a$'dan küçük olmayan en küçük tamsayı olarak tanımlanır, bu durumda  $\lceil a \rceil=2$ olur. 
::: 

::: {#exm-kartil1}
Örneğin 11 gözlemli bir veri kümesinde birinci kartili, $Q_1$, hesaplamak istediğimizi düşünelim. $k=0.25(11+1)=3$ bir tamsayı olduğu için birinci kartil $Q_1=x_{(k)}=x_{(3)}$, yani üçüncü sıradaki gözlem olur. 

Örnek olarak öğrenci notları verisini düşünelim: 
```{r}
gpa <- c(3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9, 2.7)
rbind(`sıra` = 1:11, `sıralı_gpa` = sort(gpa))
```
Burada $x_{(3)}=2.5$ olduğu için birinci kartil $Q_1=2.5$ olarak bulunur. 
::: 

::: {#exm-kartil2}
$n=10$ gözlemli bir veri kümesinde ise $0.25(10+1)=2.75$ bir tamsayı olmadığı için ikinci ve üçüncü sıradaki değerlerin interpolasyonu ile bulunur. Örneğin,
```{r}
x <- c(1:10)*10
rbind(`sıra` = 1:10, `sıralı_x` = sort(x))
```
veri kümesinde $j=1$ kartili 

\begin{align*}
Q_1 &= x_{(2)} + (2.75 - 2) \cdot (x_{(3)} - x_{(2)})\\
    &= 20+ 0.75\cdot(30-20)\\
    &= 27.5
\end{align*}

olur. Yani, 3. sıradaki gözlem (30) ile 2. sıradaki gözlem (20) arasındaki farkın dörtte üçünü (0.75*10=7.5) 2. sıradaki gözleme ekliyoruz. 

İkinci kartili hesaplayalım. $j=2$, $jk=0.5(11)=5.5$ ve $\lfloor jk \rfloor=5$ olduğuna göre 

\begin{align*}
Q_2 &= x_{(5)} + (5.5-5) \cdot (x_{(6)} - x_{(5)})\\
    &= 50+ 0.5\cdot(60-50)\\
    &= 55  
\end{align*}

bulunur. 5. ve 6. sıradaki gözlemlerin farkının yarısını alıyoruz (0.5*10=5) ve 5. gözleme ekliyoruz. Bu aynı zamanda medyandır. 

Üçüncü kartili, $Q_3$, hesaplayalım. Bu durumda $j=3$, $jk=0.75(11)=8.25$ ve $\lfloor jk \rfloor=8$ olduğuna göre 

\begin{align*}
Q_3 &= x_{(8)} + (8.25-8) \cdot (x_{(9)} - x_{(8)})\\
    &= 80+ 0.25\cdot(90-80)\\
    &= 82.5  
\end{align*}

bulunur. 8. ve 9. sıradak gözlemlerin farkının dörtte birini 8. sıradaki gözleme ekliyoruz. 

:::

`R`'da kantillerin ve çeyrekliklerin hesaplanmasında `quantile()` fonksiyonu kullanılabilir. Bu fonksiyon kantillerin hesaplanmasında farklı algoritmalar kullanır. Kullanıcılar `type` girdisini seçerek istedikleri algoritmaya göre kantilleri hesaplayabilirler. Bu algoritmalar interpolasyonun türüne göre farklılaşmaktadır. `R`'ın varsayılan  algoritması Hyndman ve Fan yöntemini (`type = 7`) kullanmaktadır: 
```{r}
quantile(x, probs = c(0.25, 0.5, 0.75), type = 7)
```
Bu algoritma ile bulunan kartiller biraz farklıdır. Yukarıda açıkladığımız yöntemi uygulamak için `type=6` opsiyonu kullanılabilir: 
```{r}
quantile(x, probs = c(0.25, 0.5, 0.75), type = 6)
```

Küçük veri kümelerinde farklılık gösterse de bu algoritmalar daha büyük verilerde birbirine yaklaşık sonuçlar verir. 

::: {#exm-kartil3}
Hanehalkı örnekleminde aylık gelirin kartillerini bulalım. 

```{r}
# type=7
quantile(hane_ornek$aylik_gelir, 
         probs = c(0.25, 0.5, 0.75), 
         type = 7)
```

```{r}
# type=6
quantile(hane_ornek$aylik_gelir, 
         probs = c(0.25, 0.5, 0.75), 
         type = 6)
```
Her iki yöntem birbirine benzer sonuçlar vermiştir. Buna göre hanehalklarının %25'inin aylık geliri 1883 TL'den, %50'sinin 2863 TL'den, ve %75'inin 4530 TL'den düşüktür. 
::: 



<!-- $$ -->
<!-- \text{Q1} = x_{\left(\left\lfloor \frac{n+1}{4} \right\rfloor\right)} + \left(\frac{n+1}{4} - \left\lfloor \frac{n+1}{4} \right\rfloor\right) \times \left(x_{\left(\left\lfloor \frac{n+1}{4} \right\rfloor + 1\right)} - x_{\left(\left\lfloor \frac{n+1}{4} \right\rfloor\right)}\right) -->
<!-- $$ -->


<!-- $$ -->
<!-- \begin{align*} -->
<!-- Q1 &= \begin{cases} -->
<!--     x_{(k)} & \text{if } k \text{ is an integer} \\ -->
<!--     x_{\lfloor k \rfloor} + (k - \lfloor k \rfloor) \cdot (x_{\lfloor k \rfloor + 1} - x_{\lfloor k \rfloor}) & \text{if } k \text{ is not an integer} -->
<!--     \end{cases} \\ -->
<!-- Q2 &= \begin{cases} -->
<!--     x_{(2k)} & \text{if } 2k \text{ is an integer} \\ -->
<!--     x_{\lfloor 2k \rfloor} + (2k - \lfloor 2k \rfloor) \cdot (x_{\lfloor 2k \rfloor + 1} - x_{\lfloor 2k \rfloor}) & \text{if } 2k \text{ is not an integer} -->
<!--     \end{cases} \\ -->
<!-- Q3 &= \begin{cases} -->
<!--     x_{(3k)} & \text{if } 3k \text{ is an integer} \\ -->
<!--     x_{\lfloor 3k \rfloor} + (3k - \lfloor 3k \rfloor) \cdot (x_{\lfloor 3k \rfloor + 1} - x_{\lfloor 3k \rfloor}) & \text{if } 3k \text{ is not an integer} -->
<!--     \end{cases} -->
<!-- \end{align*} -->
<!-- $$ -->

<!-- $$ -->
<!-- Q_1 = x_{(\lceil 0.25n \rceil)}, \quad Q_2 = x_{(\lceil 0.50n \rceil)}, \quad Q_3 = x_{(\lceil 0.75n \rceil)} -->
<!-- $$ -->


::: {#def-yuzdelik}

## Yüzdelik  

Yüzdelikler (percentile), kantillerin bir başka özel durumudur ve veri kümesini yüzdelik dilimlere böler. Örneğin, 90. yüzdelik dilim, veri setindeki gözlemlerin %90'ının bu değerin altında olduğunu belirtir.

Genel olarak $p$ yüzdeliği gözlemlerin yaklaşık %$p$ kadarının küçük olduğu değere eşittir. Sıralanmış bir veri kümesinde $(n+1)p/100$ pozisyonundaki değer olarak bulunabilir. Benzer şekilde ondalıklar (decile) da tanımlanabilir. 
:::

::: {#exm-yuzdelik1}
R'da yüzdelikleri hesaplamak için `quantile()` fonksiyonu kullanılabilir: 
```{r}
# R ile kantil hesabı  
quantile(hane_ornek$yillik_gelir, 
         probs = c(0.1, 0.25, 0.9))
```
Buna göre hanelerin %10'unun yıllık geliri 15583.23 TL'den düşüktür. Benzer şekilde 22598.81 TL'den daha az yıllık geliri olan hanelerin oranı %25'dir. Hanelerin %90'ının geliri 81032.53 TL'den düşüktür. 
:::  



## Değişkenlik Ölçüleri {#betimsel-degiskenlik}

Bir veri kümesindeki merkezi eğilimin yanı sıra, değerlerin ne kadar yayıldığını ya da  birbirinden ne kadar farklı olduğunu belirlemek, verilerin doğasını anlamak için önemlidir. Değişkenlik ölçüleri, bu yayılımı ölçmek ve verilerin dağılımı hakkında bilgi sahibi olmak için kullanılır.

```{r}
#| label: fig-degiskenlik1
#| fig-cap: "Ortalaması aynı değişkenliği farklı iki veri kümesi"
#| fig-subcap: 
#|   - "Birinci sınav sonucu, ortalama = 75"
#|   - "İkinci sınav sonucu, ortalama = 75" 
#| layout-ncol: 2
#| fig-width: 4
#| fig-height: 3
#| warning: false
#| echo: false
#| 
notlar1 <- c(65,70,75,80,85,80,85,65,70)
ort1 <- mean(notlar1)
notlar2 <- c(52,58,80,90,95,60,55,90,95)
ort2 <- mean(notlar2)

par(bty = "n")
stripchart(notlar1, method = "stack", xaxt='n',
           pch = 19, at = 0, xlim = c(50,100), cex.axis=0.8,
           col = "black", xlab = "Not")
axis(1, at = seq(50, 100, by = 5))
abline(v = ort1, col = "black", lty = 2)

par(bty = "n")
stripchart(notlar2, method = "stack", xaxt='n',
           pch = 19, at = 0, xlim = c(50,100),
           col = "black", xlab = "Not")
axis(1, at = seq(50, 100, by = 5))
abline(v = ort2, col = "black", lty = 2)
```
@fig-degiskenlik1 iki sınav sonucuna ilişkin notları göstermektedir. Her iki sınavın ortalaması 75'dir. Birinci sınavın notları ortalama çevresinde daha dar bir aralıkta dağılmaktadır. İkinci sınavın sonuçları ise daha geniş bir aralıkta değerler almaktadır. 

### Aralık 

Aralık (range), verideki en büyük ve en küçük değer arasındaki farktır. Sıralanmış gözlemlerde 
$$
\mbox{Aralık} = x_{(n)} - x_{(1)}
$$
formülüyle kolayca bulunabilir. @fig-degiskenlik1 verilerine göre birinci sınavın aralığı $85-65=20$, ikinci sınavın aralığı ise $95-52=43$ olarak bulunur. Ortalaması aynı olan bu veri kümelerinde aralığı daha geniş olan daha yüksek değişkenliğe sahiptir diyebiliriz. 

Aralık ölçüsü değerlerin genel dağılımı hakkında bir fikir verse de tek başına çok kısıtlı bir bilgi sağlar. Özellikle uç değerlerin varlığı aralığı doğrudan etkiler. Örneğin notları 0 ve 100 olan iki öğrenci olsaydı aralık 100 olurdu.  Uç değerlere fazla duyarlı olduğu için aralık yerine dağılımın yüzde ellilik orta kısmındaki değerler aralığına bakmak isteyebiliriz. Buna **kartiller aralığı** denir. 


### Kartiller Aralığı 

Kartiller, daha önce tanımladığımız gibi, gözlemlerin dört eşit parçaya bölündüğü noktalardır. Veriler küçükten büyüğe sıralandığında, ilk, ikinci (medyan), ve üçüncü kartiller hesaplanır. Kartiller aralığı üçüncü kartil ile birinci kartil arasındaki fark olarak tanımlanır: 

$$
IQR  = Q_3-Q_1
$$ {#eq-kartil1}
Burada $Q_3$ gözlemlerin %75'inin küçük olduğu üçüncü kartil değerini, $Q_1$ ise %25'inin küçük olduğu birinci kartil değerini göstermektedir. 

::: {#exm-kartil1}
13 öğrencinin not verisi aşağıdaki gibidir.  
```{r}
not <- c(48, 55, 87, 58, 63, 77, 90, 68, 85, 80, 60, 52, 66)
rbind(sira = 1:length(not), sirali_not = sort(not))
```
Buna göre medyan ($Q_2$) yedinci sıradaki değerdir: 66. Birinci ve üçüncü kartiller ise  
```{r}
kartiller <- quantile(not, probs = c(0.25, 0.5, 0.75), type = 6)
kartiller
```
$Q_1=56.5$ ve $Q_3=82.5$ olarak bulunur. Öğrencilerin %25'i 56.5'den, %75'i 82.5'den düşük not almıştır. Bu ikisi arasındaki fark 
```{r}
IQR <- kartiller[3]-kartiller[1]
IQR
```
kartiller aralığıdır, $IQR=26$. Bu dağılımın ortasında yer alan gözlemlerin aralığı olarak düşünülebilir. Özellikle uç değerlerin varlığı durumunda aralık yerine dördebölenler aralığı tercih edilebilir. 
:::

### Varyans 

Varyans bir veri kümesinde merkez çevresindeki değişkenliğin bir ölçüsüdür. Verilerin anakütleye ya da örnekleme ait olmasına göre farklı şekilde tanımlanır. 
Örneklem ya da anakütle varyansını hesaplamanın ilk adımı her bir gözlem değerinin ortalamaya olan uzaklığının hesaplanmasıdır. 

Ortalaması $\mu=\sum_i X_i/N$ olan bir anakütlede gözlem değerlerini $(X_1, X_2,\ldots,X_N)$ ile gösterelim. Tipik elemanı $X_i$ olan bu gözlem kümesinde her bir değerin anakütle ortalaması ile farkını, $X_i-\mu$, hesaplayabiliriz. Böylece her bir gözlemin
$$
(X_1-\mu),(X_2-\mu),(X_3-\mu),\ldots,(X_n-\mu)
$$
merkeze olan uzaklığını bulabiliriz. Fark pozitif işaretliyse bu gözlemin ortalamanın üzerinde, negatif işaretliyse ortalamanın altında olduğunu gösterir. Mutlak büyüklüğü ise uzaklığa ilişkin bilgi içerir. 

Bu farklardan hareketle bir değişkenlik ölçütü oluşturabilir miyiz? Ortalamadan farkların toplamını aldığımızı düşünelim: 

\begin{align}
\nonumber \sum_{i=1}^N (X_i-\mu)&= (X_1-\mu)+(X_2-\mu)+(X_3-\mu)+\ldots +(X_N-\mu)\\
    &= (X_1+X_2+X_3+\ldots+X_N)-N\mu\\
\nonumber    &= N\mu - N\mu\\
\nonumber    &= 0
\end{align}

Burada $X_i$'lerin toplamının tanım gereği $N\mu$ olduğuna dikkat ediniz. Bu farkların toplamı, gözlem kümesi ne olursa olsun 0 olduğu için bir değişkenlik ölçütü olamaz. 

Ortalamadan büyük ve küçük olan gözlemlere eşit ağırlık veren bir değişkenlik ölçütü geliştirmenin bir yolu bu farkların karesini almaktır: 
$$
(X_1-\mu)^2,(X_2-\mu)^2,(X_3-\mu)^2,\ldots,(X_n-\mu)^2
$$
Ortalamadan uzaklığın karelerinin toplamından hareketle bir değişkenlik ölçütü oluşturabiliriz. Buna varyans adı verilir. 

::: {#def-popvar}

## Anakütle varyansı, $\sigma^2$

Anakütle varyansı, gözlem değerlerinin anakütle ortalamasına olan uzaklığının karelerinin toplamının gözlem sayısına bölünmesiyle bulunur: 
$$
\sigma^2  =\frac{1}{N}\sum_{i=1}^N (X_i-\mu)^2
$$ {#eq-varyans1}

Genellikle $\sigma^2$ ile gösterilir ve *sigma-kare* şeklinde okunur. Varyans hiç bir zaman negatif olamaz. Tüm gözlemler aynı değere eşitse, yani sabit gözlemler için varyans 0 olur.  

Aşağıda verilen kısa yol formülüyle ortalamadan farkları almadan da varyansı hesaplayabiliriz: 

\begin{align}
\nonumber \sigma^2 &= \frac{1}{N}\sum_{i=1}^N (X_i-\mu)^2\\
\nonumber    &= \frac{1}{N}\sum_{i=1}^N (X_i^2-2\mu X_i + \mu^2)\\
    &= \frac{1}{N}\sum_{i=1}^N X_i^2-2\mu \frac{1}{N}\sum_{i=1}^N X_i + \frac{1}{N}N\mu^2\\
\nonumber    &= \frac{1}{N}\sum_{i=1}^N X_i^2-2\mu^2 + \mu^2\\
\nonumber    &= \frac{1}{N}\sum_{i=1}^N X_i^2-\mu^2
\end{align}
::: 

::: {#exm-varyans1}

$X$ değişkeninin anakütle değerleri $(65,70,75,80,85,80,85,65,70)$ olsun. Anakütle ortalaması $\mu = 75$ olmak üzere @tbl-varyans1 varyans hesaplaması için gerekli büyüklükleri göstermektedir. 


| $i$    | $X_i$  | $X_i - \mu$    | $(X_i - \mu)^2$    | $X_i^2$            |             
|--------|--------|---------------:|-------------------:|-------------------:|
| 1      | 65     | -10            | 100                | 4225               | 
| 2      | 70     | -5             | 25                 | 4900               |
| 3      | 75     | 0              | 0                  | 5625               |
| 4      | 80     | 5              | 25                 | 6400               |
| 5      | 85     | 10             | 100                | 7225               | 
| 6      | 80     | 5              | 25                 | 6400               | 
| 7      | 85     | 10             | 100                | 7225               |
| 8      | 65     | -10            | 100                | 4225               |
| 9      | 70     | -5             | 25                 | 4900               |  
|Toplam  | 675    | 0               | 500                | 51125              |


: $N=9$ gözlemli bir anakütle için varyans hesaplama tablosu {#tbl-varyans1}

Bu tablodan hareketle anakütle varyansı 
$$
\sigma^2  =\frac{1}{N}\sum_{i=1}^N (X_i-\mu)^2 = 500/9=55.56
$$
olarak bulunur. Kısa yol formülünü kullanarak 
$$
\sigma^2  = \frac{1}{N}\sum_{i=1}^N X_i^2-\mu^2 = 51125/9 - 75^2 = 55.56
$$
aynı sonuca ulaşılabilir. 
::: 


Benzer şekilde, örneklem varyansı gözlemlerin örneklem ortalamasından farkının kareler toplamına dayanır. Elimizde bir örneklem olduğu için anakütle ortalamasını $\mu$ bilmeyiz. Bu nedenle varyans formülünde $\mu$ için iyi bir tahminci kullanmamız gerekir. Anakütle ortalamasının yansız bir tahmincisi örneklem ortalamasıdır. Böylece ölçütümüzü her bir örneklem değerinin aritmetik ortalamaya olan uzaklığının karesine dayandırabiliriz. 


$n$ gözlemli bir örneklemi $(x_1, x_2,\ldots,x_n)$ ile gösterelim. Örneklem ortalaması $\bar{x}=\sum_i X_i/n$ olsun. Tipik elemanı $x_i$ olan bu gözlem kümesinde her bir değerin örneklem ortalaması ile farkını, $x_i-\bar{x}$, hesaplayabiliriz. Böylece her bir gözlemin
$$
(x_1-\bar{x}),(x_2-\bar{x}),(x_3-\bar{x}),\ldots,(x_n-\bar{x})
$$
örneklem ortalamasına ne kadar uzak olduğunu bulabiliriz. Anakütle ortalamasından farkların toplamının 0 olduğunu göstermiştik. Örneklem ortalamasından farkların toplamının da 0 olduğu kolayca gösterilebilir: 
 
\begin{align}
\nonumber \sum_{i=1}^n (x_i-\bar{x})&= (x_1-\bar{x})+(x_2-\bar{x})+(x_3-\bar{x})+\ldots +(x_n-\bar{x})\\
    &= (x_1+x_2+x_3+\ldots+x_N)-n \bar{x}\\
\nonumber    &= n \bar{x} - n \bar{x}\\
\nonumber    &= 0
\end{align}


::: {#def-samplevar}

## Örneklem varyansı, $s^2$

$n$ gözlemli bir veri kümesi için örneklem varyansı 
$$
s^2  =\frac{1}{n-1}\sum_{i=1}^N (x_i-\bar{x})^2
$$ {#eq-varyans2}
olarak tanımlanır. Burada fark karelerinin toplamının gözlem sayısına değil, $n-1$'e bölündüğüne dikkat ediniz. Daha sonra detalı olarak inceleyeceğimiz gibi, örneklem varyansı, $s^2$, bilinmeyen anakütle varyansının sapmasız/yansız bir tahmincisidir. 
:::  



Örneklem varyansının kısa yol formülü aşağıda türetilmiştir:  

\begin{align}
\nonumber s^2 &= \frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})^2\\
\nonumber     &= \frac{1}{n-1}\sum_{i=1}^n (x_i^2-2\bar{x} x_i + \bar{x}^2)\\
    &= \frac{1}{n-1}\left( \sum_{i=1}^n x_i^2 - 2\bar{x} \sum_{i=1}^n x_i + n\bar{x}^2 \right)\\
\nonumber    &= \frac{1}{n-1}\left( \sum_{i=1}^n x_i^2-2n\bar{x}^2 + n\bar{x}^2 \right)\\
\nonumber    &= \frac{1}{n-1}\left( \sum_{i=1}^n x_i^2-n\bar{x}^2 \right)
\end{align}


::: {#exm-varyans2}

Hanahalkı anakütlesinden 7 gözlemli bir örneklem rassal olarak çekilmiştir. Hanelerin aylık harcama tutarları TL cinsinden aşağıda verilmiştir: 
$$
\{2600, 3600, 2150, 3600, 5250, 2350, 3200\}
$$

| $i$    | $x_i$  | $x_i - \bar{x}$| $(x_i - \bar{x})^2$| $x_i^2$            |             
|--------|--------|---------------:|-------------------:|-------------------:|
| 1      | 2600   | -650           | 422500             | 6760000            | 
| 2      | 3600   | 350            | 122500             | 12960000           |
| 3      | 2150   | -1100          | 1210000            | 4622500            |
| 4      | 3600   | 350            | 122500             | 12960000           |
| 5      | 5250   | 2000           | 4000000            | 27562500           | 
| 6      | 2350   | -900           | 810000             | 5522500            | 
| 7      | 3200   | -50            | 2500               | 10240000           | 
|Toplam  | 22750  | 0              | 6690000            | 80627500           |


: $n=7$ gözlemli harcama örneklemi varyans hesaplama tablosu {#tbl-varyans2}

Örneklem ortalaması $\bar{x}=22750/7=3250$ TL'dir. Örneklem varyansı
$$
s^2  =\frac{1}{n-1}\sum_{i=1}^N (x_i-\bar{x})^2=\frac{1}{7-1}6,690,000.00=1,115,000
$$
olarak bulunur. Kısa yol formülüyle de bulunabilir: 
\begin{align}
\nonumber s^2 &= \frac{1}{n-1}\left( \sum_{i=1}^n x_i^2-n\bar{x}^2 \right)\\
              &= \frac{1}{7-1}\left( 80627500-7\cdot 3250^2\right) \\
\nonumber    &= \left( 80627500-73937500\right)/6\\
\nonumber    &= 1115000
\end{align}


R ile harcama verisi için örneklem varyansını hesaplayalım: 
```{r}
harcama <- c(2600, 3600, 2150, 3600, 5250, 2350, 3200)
ort <- mean(harcama)
df <- data.frame(x = harcama,
                 x_xbar = harcama-ort, 
                 x_xbar2 = (harcama-ort)^2, 
                 x2 = harcama^2)
df
```
Buradan örneklem varyansı
```{r}
n <- length(harcama)
sum(df[, "x_xbar2"])/(n-1)
```
olur. Örneklem varyansı `var()` fonksiyonu ile de bulunabilir: 
```{r}
var(harcama)
```
:::

 
Varyans (örneklem ya da anakütle) sadece negatif olmayan değerler alır, yani ya 0 olur ya da pozitif değerler alır. Varyansın 0 olması verilerde değişkenlik olmadığı anlamına gelir (sabit değerlerden oluşur). Diğer taraftan varyansın mutlak yorumu karelerinin alınmasından dolayı zordur. Verilerin ölçü birimi cinsinden yorumu kolaylaştırmak için *standart sapma* kullanılabilir. 



### Standart Sapma 

Harcama verisinde ortalama 3750 TL'ye karşılık varyans 1115000 olarak bulunmuştu. Bu değeri nasıl yorumlayabiliriz? Varyansın tanımında ortalamaya uzaklığın karesini aldığımız için değişkenin ölçü birimi ile yorum yapamayız.  Orijinal ölçü birimine dönmek için varyansın karekökünü alabiliriz. Böylece hanelerin aylık harcaması 3750 TL ve standart sapması 1056 TL'dir diyebiliriz. 

::: {#def-popsd}

## Anakütle standart sapması, $\sigma$

Anakütle standart sapması, anakütle varyansının (pozitif) kareköküdür: 

$$
\sigma = \sqrt{\sigma^2}  =\sqrt{\frac{1}{N}\sum_{i=1}^N (X_i-\mu)^2}
$$ {#eq-std1}
:::  

::: {#def-samplesd}

## Örneklem standard sapması, $s$

Örneklem standart sapması, örneklem varyansının (pozitif) kareköküdür:

$$
s = \sqrt{s^2}  =\sqrt{\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})^2}
$$ {#eq-std2}
:::  

Standart sapma verilerin yayılımını daha kolay yorumlamak için kullanılabilir. Daha düşük bir standart sapma, verilerin ortalamaya daha yakın dağıldığını, yüksek bir standart sapma ise verilerin daha geniş bir aralıkta yayıldığını gösterir.



### Chebyshev Teoremi 

Anakütle standart sapmasını yorumlamanın bir yolu, verilerin ne kadarının ortalamadan kaç standart sapma uzağında olduğunun bulunmasıdır. Chebyshev teoremi ya da kuralı bunun için her anakütle için geçerli bir yol sunar. 

::: {#thm-chebyshev}

## Chebyshev 

Ortalaması $\mu$ ve standart sapması $\sigma$ olan bir anakütlede, $k>1$ olmak üzere, verilerin en az 
$$
\% ~\left( 1-\frac{1}{k^2} \right)\times100
$$ {#eq-chebyshev1}
kadarı ortalamadan en çok $k$ standart sapma uzaklıktadır. 

Örneğin, $k=2$ ise, verilerin $\%~100(1-1/4)=\% ~75$ kadarı 2 standart sapma içinde yer alır. Alt sınırı $\mu-2\sigma$ ve üst sınırı $\mu+2\sigma$ olan bir aralık belirlersek verilerin yaklaşık %75'i bu aralık içinde yer alacaktır. 

Benzer şekilde $k=3$ ise verilerin %$100(1-1/9)$ yani % 88.89 kadarı 3 standart sapma içinde yer alır.  
::: 

Chebyshev teoreminin bu versiyonu simetrik olsun olmasın her dağılım için geçerlidir. Simetrik dağılımlar için daha spesifik bir aralık belirlenebilir. 

::: {#thm-chebyshev2}

## Chebyshev (Normal dağılım)

Çan biçimli simetrik  dağılmış bir anakütle için verilerin yaklaşık 

  - $\%68$'i ortalamadan $1$ standart sapma uzaklıkta, yani $\mu \pm\sigma$ aralığı içinde,  
  - $\%95$'i ortalamadan $2$ standart sapma uzaklıkta, yani $\mu \pm 2\sigma$ aralığı içinde, ve 
  - $\%99.7$'si ortalamadan $3$ standart sapma uzaklıkta, yani $\mu \pm 3\sigma$ aralığı içinde 

yer alır. 
:::

```{r}
#| label: fig-chebyshev
#| fig-cap: "Chebyshev teoreminin simetrik dağılım versiyonu: gözlemlerin %95'i 2 standart sapma içinde yer alır"
#| warning: false
#| echo: false 

set.seed(123)
mu = 50
sigma = 10
n = 1000
z <- rnorm(n, mean = mu, sd = sigma)
x <- round(z)

# Calculate mean and standard deviation
mean_data <- mean(x)
sd_data <- sd(x)

# Define k value for Chebyshev's theorem
k <- 2

# Calculate the Chebyshev bounds
lower_bound <- mu - k * sigma
upper_bound <- mu + k * sigma

par(bty = "n")
par(cex.axis = 0.8, cex.lab = 0.8)  # Eksen etiketleri ve başlıkları için metin boyutunu ayarlama
stripchart(x, method = "stack", xaxt='n',
           pch = 19, at = 0,
           xlim = c(min(x),max(x)),
           cex = 0.5,
           col = "gray",
           xlab = "Gözlem değerleri")
#axis(1, at = seq(round(min(x)), round(max(x)), by = 5))
axis(1, at = seq(0,100, by = 5))
abline(v = 50, col = "red", lty = 2)
# Add Chebyshev bounds
abline(v = lower_bound, col = "black", lty = 2, lwd = 1)
abline(v = upper_bound, col = "black", lty = 2, lwd = 1)
text(mu, 1.5, labels = expression(mu == 50), col = "black", pos = 4)

text(lower_bound, 0.3, labels = expression(mu - 2 * sigma), col = "black", pos = 2)
text(upper_bound, 0.3, labels = expression(mu + 2 * sigma), col = "black", pos = 4)
```
::: {#exm-chebyshev1}

Ortalaması $\mu=50$ ve varyansı $\sigma^2=100$ olan normal dağılmış bir anakütlede gözlemlerin %95'i $\mu-2\sigma=30$ ve $\mu+2\sigma=70$ aralığı içinde yer alır. @fig-chebyshev bu aralığı göstermektedir. Gözlemlerin %68'i bir standart sapma içinde, yani, 40-60 aralığında değerler almaktadır. Gözlemlerin neredeyse tamamı 3 standart sapma içindedir (20-80). 
::: 


::: {#exm-chebyshev2}
Türkiye'de il düzeyinde 2013 yılı mutluluk verilerini anakütle olarak düşünelim: 
```{r}
load("Data/mutluluk.rda")
xbar <- mean(mutluluk$mutluluk)
s2 <- var(mutluluk$mutluluk)
s <- sd(mutluluk$mutluluk)
z <- (mutluluk$mutluluk-xbar)/s
c(ortalama = xbar, varyans = s2, stdsapma = s)
```
Dağılım hakkında ek bir bilgimiz olmadığını varsayalım. Buna göre mutluluk düzeyi ortalaması 61 ve standart sapması 7.5 olan bir dağılıma sahiptir. Buradan hareketle gözlemlerin yaklaşık %75'inin 46 ile 76 arasında değerler aldığını söyleyebiliriz. Simetrik bir dağılıma sahipse verilerin %95'i bu aralıkta yer alacaktır. 
:::  

### Değişkenlik Katsayısı 

Değişkenlik katsayısı (*coefficient of variation*, CV) verideki değişkenliğin  ortalamaya göre ne kadar büyük olduğunu gösteren istatistiksel bir ölçüttür. Varyasyon ya da değişkenlik katsayısı, standart sapmanın, ortalamaya oranının yüzdesi olarak hesaplanır ve genellikle yüzde ile ifade edilir. Bu katsayı, birimlerden bağımsız olduğu için farklı birimlere sahip verileri karşılaştırmak için uygundur.

::: {#def-popcv}

## Anakütle değişkenlik katsayısı

Anakütle standart sapmasının anakütle ortalamasına oranı olarak 
$$
CV = \%100\cdot \frac{\sigma}{\mu}
$$ {#eq-popCV}
tanımlanır. 
::: 

::: {#def-samplecv}

## Örneklem değişkenlik katsayısı

Örneklem standart sapmasının örneklem ortalamasına oranı olarak 
$$
\widehat{CV} = \%100\cdot \frac{s}{\bar{x}}
$$ {#eq-sampleCV}
tanımlanır. 
::: 

Görece yüksek bir CV gözlemlerin ortalama göre daha fazla değişkenliğe sahip olduğunu gösterir. Veriler daha yayıktır. 

::: {#exm-samplecv}
Bir grup öğrencinin iki sınava ait sonuçları şöyledir: 
$$
\mbox{1. Sınav:}\quad \bar{x}=74,\quad s=8
$$
$$
\mbox{2. Sınav:}\quad \bar{x}=52,\quad s=15
$$
Örneklem değişkenlik katsayılarını bulun ve yorumlayın. 

**Çözüm**: 
$$
\mbox{1. Sınav:}\quad \widehat{CV} = \%100\cdot \frac{s}{\bar{x}}=\%100\cdot \frac{8}{74}=\%10.81
$$
$$
\mbox{2. Sınav:}\quad \widehat{CV} = \%100\cdot \frac{s}{\bar{x}}=\%100\cdot \frac{15}{52}=\% 28.85
$$
Buna göre 2. sınavın varyasyon katsayısı daha yüksektir. İkinci sınavda notlar ortalamaya göre daha büyük değişkenlik gösterir. Bu oranlar, standart sapmanın büyüklüğünün tek başına yeterli olmadığını vurgular. Örneğin, her iki sınavın standart sapması aynı olsaydı bile, ortalamaları farklı olduğu için değişkenlik katsayıları farklı olurdu. CV yardımıyla iki farklı sınavın performanslarını ve göreceli değişkenliklerini daha anlamlı bir şekilde kıyaslayabiliyoruz. 
:::  


## Biçim Ölçüleri {#betimsel-bicim}

Verilerin dağılımının simetrikliği, uçlarda ve merkezdeki davranışları (örneğin basıklık ve kuyruk kalınlığı), görsel araçlarla birlikte analiz edildiğinde anlamlı bilgiler sağlar. Bu bölümde, dağılımın şeklini betimleyen istatistikleri inceleyeceğiz. Özellikle histogram, kutu grafiği ve yoğunluk grafikleriyle çalışırken, bu biçim ölçülerini de kullanacağız.

### Çarpıklık 

Çarpıklık, bir dağılımın simetrik olup olmadığı hakkında bilgi verir.  Simetrik bir dağılımın sağ ve sol tarafı birbirine benzer bir şekle sahiptir. Böyle bir dağılım için medyan değeri ortalama değerine eşittir. 


Örneklem çarpıklık katsayısı
$$
c = \frac{m_3}{s^3} = \frac{{\frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^3}}{{\left( \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2 \right)^{3/2}}}
$$ {#eq-carpiklik1}
formülüyle hesaplanabilir. Burada $c$ örneklem çarpıklık katsayısını, $\bar{x}$ örneklem ortalamasını, $s$ örneklem standart sapmasını göstermektedir. Bu istatistiğin payında yer alan ifade  $x$'in örneklemdeki üçüncü momentidir: $m_3$.  Payda her zaman pozitif değerler alırken, pay sıfır, negatif ya da pozitif olabilir: 
   - $c=0$ ise dağılım simetrik, 
   - $c>0$ ise pozitif-çarpık ya da  sağa çarpık, 
   - $c<0$ ise sola-çarpıktır (negatif çarpık). 
   
Simetrik dağılımlar için 
$$
medyan=ortalama=mod
$$ 
olur. 

Sağa çarpık dağılımlar için 
$$
ortalama > medyan
$$
olur. Bunun nedeni sağa çarpık dağılımlarda büyük değerlerin fazla ağırlığa sahip olmasıdır. 

Sola çarpık dağılımlar için ise 
$$
medyan > ortalama
$$
olur.   

::: {#exm-carpiklik1}

Aşağıdaki not ortalaması verisinde çarpıklık katsayısını `R` ile hesaplayınız.  
```{r}
gpa <- c(3.2, 1.8, 2.5, 2.8, 3.7, 3.1, 2.9, 2.0, 3.5, 3.9)
```

@eq-carpiklik1 formülündeki bileşenleri hesaplayalım: 
```{r}
gpa_ort <- mean(gpa)
gpa_medyan <- median(gpa)
gpa_s <- sd(gpa)
gpa_carpiklik <- sum((gpa - gpa_ort)^3) / (length(gpa) * gpa_s^3)
gpa_carpiklik
```
Çarpıklık katsayısı yaklaşık $-0.27$ olarak bulundu. Bu değer negatif olduğu için dağılımın hafif sola çarpık olduğunu söyleyebiliriz. Örneklem ortalaması (2.94) medyandan (3) biraz daha küçük bulunmuştur.  

Örneklem çarpıklık katsayısını hesaplayan aşağıdaki gibi bir R fonksiyonu da yazabiliriz: 
```{r}
# örneklem çarpıklık katsayısı için fonksiyon
# Bu fonksiyon, örneklemdeki üçüncü merkezi momenti ve standart sapmayı 
# kullanarak çarpıklık katsayısını hesaplar
carpiklik <- function(x) {
  n <- length(x)
  mean_x <- mean(x)
  sd_x <- sd(x)
  carpiklik <- sum((x - mean_x)^3) / (n * sd_x^3)
  return(carpiklik)
}
```

Bu fonksiyonu kullanarak
```{r}
carpiklik(gpa)
```
buluruz. 
:::


::: {#exm-carpiklik2}

Yukarıda yazdığımız `carpiklik()` fonksiyonunu kullanarak hanahalkı örneklemindeki aylık harcama değişkeninin çarpıklık katsayısını hesaplayınız. Örneklem ortalaması ve medyanını da hesaplayınız ve yorumlayınız. 

```{r}
carpiklik(hane_ornek$aylik_harcama)
```
Aylık hane harcamasının çarpıklık katsayısı yaklaşık 5.99 olarak bulunmuştur. Bu değişken sağa çarpık bir dağılıma sahiptir. Başka bir ifadeyle hanelerin önemli bir kısmı düşük ve orta düzeydeki değerlerde yoğunlaşmıştır. Aylık harcama düzeyi arttıkça hane sayısı azalmaktadır. 

Böyle bir dağılımda göreceli yüksek ve uç değerlerin varlığı ortalamanın yüksek çıkmasına neden olabilir. Bu değişken için 

```{r}
mean(hane_ornek$aylik_harcama)
median(hane_ornek$aylik_harcama)
```
örneklem ortalaması 3261.18 TL, örneklem medyanı ise 2584.41 TL olarak bulunmuştur. Tipik olarak ortalamanın medyandan büyük olması çarpıklığın pozitif olduğuna işaret eder. Genel olarak fertlerin ya da hanelerin gelir dağılımları sağ kuyruğun daha uzun olduğu, yani düşük ve orta gelirli gözlemlerin ağırlıkta olduğu bir davranışa sahiptir.  
::: 

Çarpıklık dağılımın simetrikliğine ilişkin bilgi verir. Basıklık katsayısı ise kuyrukların (merkezden uzak değerlerin) dağılımına ilişkin bilgi içerir. Bu ölçüleri dağılım grafiklerini incelerken tekrar ele alacağız. 

### Basıklık 

Basıklık, bir dağılımın tepesi etrafında nasıl yoğunlaştığını ve kuyrukların ne kadar uzun olduğunu belirten bir ölçüdür. Örneklem basıklık katsayısı
$$
b = \frac{m_4}{s^4} = \frac{\frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^4}{\left(\frac{1}{n} \sum_{i=1}^{n-1} (x_i - \bar{x})^2\right)^2}  
$$ {#eq-basiklik1}
formülüyle hesaplanabilir (büyük örneklemlerde). Burada $b$ örneklem basıklık katsayısını, $\bar{x}$ örneklem ortalamasını, $s$ örneklem standart sapmasını göstermektedir. Bu istatistiğin payında yer alan ifade  $x$'in örneklemdeki dördüncü merkezi momentidir ($m_4$). Basıklık katsayısı her zaman pozitif değerler alır. 

Basıklık katsayısı genellikle normal dağılıma göre değerlendirilir.  Normal dağılım için basıklık 3 değerini alır. Eğer $b>3$ ise dağılım normal dağılıma göre daha basıktır; yani kuyrukları daha kalındır (leptokurtosis).  Tersi durumda $b<3$ ise dağılım normale göre daha ince kuyruklara sahiptir.  

::: {#exm-kurtosis1}

Basıklık katsayısını hesaplayan `kurtosis_hesapla()` isimli bir R fonksiyonu yazınız. `bist100.rda` veri kümesinde yer alan `getiri` değişkeni için basıklık katsayısını hesaplayınız.  

```{r}
# Basıklık (kurtosis) hesaplayan fonksiyon
kurtosis_hesapla <- function(x) {
  n <- length(x)
  mean_x <- mean(x)
  m4 <- sum((x - mean_x)^4) / n
  s2 <- sum((x - mean_x)^2) / n
  kurtosis <- m4 / (s2^2)
  return(kurtosis)
}
```

```{r}
load("Data/bist100.rda")
kurtosis_hesapla(bist100$getiri[-1])
```
Basıklık katsayısı yaklaşık 8.07 olarak bulunmuştur. Bu değer 3'ten büyük olduğu için normal dağılıma göre getirinin daha kalın kuyruklara sahip olduğunu söyleyebiliriz. 
:::  



## Görsel özet araçlar 

İncelediğimiz sayısal özet istatistikler, verilerin temel özelliklerini anlamak için önemli bir ilk adımdır. Bu istatistiklerin yanı sıra, verilerin görsel temsili karmaşık sayı yığınlarının daha iyi anlaşılmasını sağlar. Bu alt bölümde öğreneceğimiz görsel araçlar, sayısal özet bilgilerin yanı sıra verilerdeki eğilimleri, dağılımları ve ilişkileri daha açık bir şekilde ortaya koyar. Görsel araçlar, verilerin ardındaki hikayeyi anlatmada güçlü bir araç olarak işlev görür. Örneğin, bir histogram, verinin dağılımını etkili bir şekilde gösterirken, bir kutu grafiği (box plot), çeyrek değerleri ve olası uç değerleri görsel olarak sunar. 

Verilerin görselleştirilmesinde değişkenin türüne göre uygun araçların seçilmesi gerekir. Kategorik değişkenler için frekans tabloları, çubuk çizimleri, pasta çizimi gibi araçlar uygundur. Sürekli değişkenler için ise histogram, dal-yaprak çizim, kutu çizimi gibi araçlar kullanılabilir.  

### Frekans tabloları ve kategorik değişkenler

Kategorik değişkenlerin gözlem kümesindeki sayısını ve oranını (yüzde) kolayca hesaplayarak bir tablo haline getirebilir ve görselleştirebiliriz. Kategorik (nominal ya da ordinal) değişkenlerin veri kümesindeki sıklığını ya da frekansını hesaplamak için `R`'da `table()` ve `prop.table(table())` fonksiyonları kullanılabilir. 

Örneğin, hanelerde sigara içenlerin sayısını ve oranını bulmak istediğimizi düşünelim. `hane_ornek.RData` verisinden hareketle

```{r}
load("Data/hane_ornek.RData")
table(hane_ornek$sigara)
prop.table(table(hane_ornek$sigara))
```
bulunur. Hanelerin yaklaşık % 51.8'inde (1036 hane) sigara içilmektedir (kategori = 1). Yaklaşık %48.2 hanede ise (964 hane) sigara içilmemektedir (kategori = 2). 


Kategorik değişkenlerin frekansları çeşitli araçlarla görselleştirilebilir. Bunlardan biri çubuk çizimidir (barplot). Örneğin, sağlık merkezlerine erişim kolaylığını hanelerin nasıl değerlendirdiğini özetlemek istiyorsak, her kategorinin sıklığını gösteren bir tablo ve çubuk çizimi oluşturabiliriz: 

```{r}
#| label: fig-barplot1
#| fig-cap: "Çubuk çizimi: sağlık merkezine erişimin kolaylığı"
#| warning: false
#| echo: true
#| # Frekans tablosu
frekans_tablosu <- sort(
  table(hane_ornek$saglik_merkezi_erisim_olcek), 
  decreasing = TRUE)
frekans_tablosu
# Frekans (yüzdelik)
frekans_tablosu_yuzde <- prop.table(frekans_tablosu) * 100
frekans_tablosu_yuzde
barplot(table(hane_ornek$saglik_merkezi_erisim_olcek), 
        ylim = c(0,1000))
```
@fig-barplot1 hanelerin sağlık merkezlerine erişim kolaylığına ilişkin 1-5 skalasında verdikleri cevapların çubuk çizimini göstermektedir. Bu grafiği sıklığa göre büyükten küçüğe sıralayarak çizebiliriz. @fig-barplot2 bu grafiği göstermektedir. 
```{r}
#| label: fig-barplot2
#| fig-cap: "Sıralanmış çubuk çizimi: sağlık merkezine erişimin kolaylığı"
#| warning: false
#| echo: true

# çubuk çizimi 
barplot(frekans_tablosu, # sıklık tablosu
        ylim = c(0,1000) # y ekseninin sınırları
        )
text(x = barplot(frekans_tablosu, plot=FALSE), 
     y = frekans_tablosu, 
     label = paste0(round(frekans_tablosu_yuzde, 1), "%"), 
     pos = 1, cex = 0.8, col = "black")
```
Buna göre hanelerin %49.1'i sağlık merkezlerine ulaşımın kolay olduğunu düşünmektedir. Sağlık merkezlerine erişimin zor olduğunu düşünen hanelerin oranı %19.4, çok zor olduğunu söyleyen hanelerin oranı ise %7.5'tir. 

Uygulamalarda yaygın olarak kullanılan başka bir grafik türü pasta grafiğidir. @fig-pasta1  `pie()` fonksiyonu ile çizilmiş örnek bir pasta grafiğini göstermektedir.  
```{r}
#| label: fig-pasta1
#| fig-cap: "Pasta grafiği: sağlık merkezine erişimin kolaylığı"
#| warning: false
#| echo: true
pie(frekans_tablosu, col = blues9)
```

Belirli bir aralıkta herhangi bir değeri alabilen sayısal değişkenleri görselleştirmenin bir çok yöntemi mevcuttur. İzleyen alt bölümlerde bunları ele alacağız. 

Frekans (sıklık) tablosu özellikle büyük boyutlu sayısal verilerin yorumlanmasında yardımcı olabilir. Bunun için veriler az sayıda gruplara (sınıflara) ayrılır ve her bir sınıfa kaç gözlem düştüğü yani sıklığı (frekansı) hesaplanır. Bu sıklıklar yüzde olarak da ifade edilebilir. 

::: {#exm-frekans1}
Bir eğitim seminerine katılanların yaşları kaydedilmiştir: 
$$
x=(22, 24, 27, 28, 30, 32, 35, 37, 40, 46).
$$ 
Bu veriyi birbirine eşit 4 parçaya ayıralım. Birinci grup: 15-25 yaş grubu 15 yaşında ya da daha büyük ve 25 yaşından küçük bireyleri kapsar. İkinci grup 25-35 yaş grubudur ve 25 (dahil) ile 35 (hariç) yaşları arasındaki bireyleri kapsar. @tbl-frekans1 bu yaş verilerinin sıklık tablosunu göstermektedir. 

| Sınıf   | Sıklık (frekans) | Yüzde Sıklık | Birikimli sıklık | % Birikimli sıklık | 
|---------|:-----------------|-------------:|:----------------:|:------------------:|
| 15-25   |        2         |      % 20    |         2        |          % 20      | 
| 25-35   |        4         |      % 40    |         6        |          % 60      | 
| 35-45   |        3         |      % 30    |         9        |          % 90      | 
| 45-55   |        1         |      % 10    |        10        |          % 100     

: Katılımcıların yaş dağılımı {#tbl-frekans1}

Frekans tablosuna (@tbl-frekans1) göre 2 gözlem, yani verilerin % 20'si 15-25 aralığında değerler almaktadır. Verilerin % 40'ı 25-35, % 30'u ise 35-45 aralığındadır. 

Sayısal verilerin sınıflara ayrılmasında  `cut()` fonksiyonu kullanılabilir: 
```{r}
yas <- c(22, 24, 27, 28, 30, 32, 35, 37, 40, 46)
yas_grup <- cut(yas, 
                breaks = c(15, 25, 35, 45,55), 
                right = FALSE # sağ sınır dahil değil
                )

# Gruplanmış yaş verisindeki frekansları hesaplayalım
frekanslar <- table(yas_grup)
print(frekanslar)
prop.table(frekanslar)
```
::: 

::: {#exm-frekans2}

32 gözlemden oluşan bir otomobil kümesinde araçların beygir gücü aşağıdaki gibidir: 
```{r}
beygir_gucu <- mtcars$hp 
# Veriyi 4x8 tablo haline getirmek için yeniden şekillendir
matrix_data <- matrix(beygir_gucu, nrow = 4, byrow = TRUE)
matrix_data
```
- `stripchart()` fonksiyonunu kullanarak verilerin basit bir görsel özetini oluşturun. 
- Gözlemleri 5 sınıfa bölün ve frekans tablosunu hazırlayın. X ekseninde sınıflar Y ekseninde sınıf içindeki gözlemler olmak üzere bir çubuk çizimi hazırlayın.  

**Çözüm**

@fig-bg1 beygir gücü verisinin nokta grafiğini göstermektedir. 
```{r}
#| label: fig-bg1
#| fig-cap: "Nokta grafiği: otomobillerin beygir gücü"
#| warning: false
#| echo: true
# Verilerin basit bir görsel özetini stripchart() kullanarak oluştur
stripchart(beygir_gucu, 
           method = "stack", 
           main = " ", 
           xlab = "Beygir Gücü", 
           col = "blue", 
           pch = 16)
```


```{r}
# Beygir gücü verilerini 5 sınıfa bölmek için sınıf aralıklarını belirle
breaks <- seq(min(beygir_gucu), max(beygir_gucu), length.out = 6)
print(breaks)
```
Bu sınır noktalarını kullanarak frekans tablosunu oluşturalım: 
```{r}
# Sınıf aralıklarına göre verileri sınıflandır
beygir_gucu_cut <- cut(beygir_gucu, 
                       breaks = breaks, 
                       include.lowest = TRUE, # en alt sınırı dahil et
                       right = FALSE          # sağ sınır hariç
                       )

# Frekans tablosunu oluştur
freq_table <- table(beygir_gucu_cut)
freq_table
```
$[52,109)$ aralığında (52 dahil, 109 hariç) 10 gözlem, $[109, 165)$ aralığında (109 dahil, 165 hariç) 9 gözlem bulunmaktadır. @fig-bg2 bu frekans tablosunun çubuk çizimini göstermektedir.  
```{r}
#| label: fig-bg2
#| fig-cap: "Beygir gücü frekans dağılımı: çubuk çizimi"
#| warning: false
#| echo: true
# Frekans tablosunu çubuk grafiği olarak çiz
barplot(freq_table, 
        main = " ", 
        xlab = "Beygir Gücü Sınıfları", 
        ylab = "Frekans", 
        col = "lightblue",  
        space=0,
        border = "black")
```

Aralıklar x ekseninde ve frekanslar y ekseninde olacak şekilde çubuk yerine nokta ile de gösterebiliriz (bkz. @fig-bg3): 
```{r}
#| label: fig-bg3
#| fig-cap: "Beygir gücü frekans dağılımı"
#| warning: false
#| echo: true
# Sınıf isimlerini al
classes <- names(freq_table)

# Çubuk grafiği yerine noktalar ve dikey çizgiler kullanarak grafiği çiz
plot(as.numeric(freq_table), 
     type = "p", 
     main = "",
     xlab = "Beygir Gücü Sınıfları", 
     ylab = "Frekans",
     col = "blue", 
     pch = 19, 
     xaxt = "n", 
     ylim = c(0,12))

# Dikey çizgiler ekle
segments(x0 = 1:length(freq_table), 
         y0 = 0, 
         x1 = 1:length(freq_table), 
         y1 = freq_table, 
         col = "lightblue", 
         lty = "dashed")

# X ekseni etiketlerini ekle
axis(1, at = 1:length(classes), labels = classes)

# Frekans sayılarını noktaların üzerine yerleştir
text(x = 1:length(freq_table), 
     y = freq_table, 
     label = freq_table, 
     pos = 3, 
     cex = 0.8, 
     col = "black")

```
:::

Sınıf sayısının ve genişliğinin frekans dağılımını doğrudan etkilediğine dikkat ediniz. Bu grafiğin özel bir versiyonu histogram adını alır. İzleyen bölümlerde bu grafik türünü inceleyeceğiz. 



### Dal-ve-yaprak

Dal-ve-yaprak (*Stem-and-Leaf*) grafiği, genellikle  az sayıda nümerik gözlemin dağılımını görselleştirmek için kullanılan bir yöntemdir. Bu grafik, veri değerlerini basit bir şekilde gruplandırarak dağılımın şeklini gösterir. Özellikle bilgisayar ya da hesaplama araçlarına erişimin olmadığı durumlarda, bir kağıt ve kalemle hızlıca çizilebilir.

İki basamaklı örnek bir veri kümesinin Dal-ve-yaprak çizimi için aşağıdaki adımlar takip edilebilir: 

- Gözlem değerleri onlar ve birler basamağı alınarak "dal" ve "yaprak" olarak adlandırılan iki parçaya ayrılır. Örneğin 75 değeri için 7 dal ve 5 yaprak olarak alınabilir. 

- "Dal" kısmı, veri değerlerinin onlar basamağından oluşur ve genellikle soldan sağa doğru sıralanır. 

- "Yaprak" kısmı, veri değerlerinin birler basamağından oluşur ve her bir "dal" için bir dizi yaprak değeri içerir.

- Her bir "dal" için yaprak değerleri, sıralanmış bir şekilde yan yana yazılır.

- Son olarak, her bir dal ile yaprak değerleri arasında bir ayraç kullanılarak dal-ve-yaprak grafiği oluşturulur.

Dal ve yaprak kısımları verilerin değerlerine göre belirlenebilir. Örneğin üç basamaklı değerler alan bir veri kümesi için dal kısmı yüzler basamağı, yaprak kısmı birler basamağı olarak seçilebilir. 

::: {#exm-stem1}

Bir sınavdan alınan 100 üzerinden puanların dal-ve-yaprak çizimini oluşturalım:   
```{r} 
not <- c(48, 55, 87, 58, 63, 75, 95, 68, 75, 80, 60, 52, 66)
stem(not)
```
Burada `|` işaretinin solunda kalan değerler "stem" (dal), sağında kalan değerler ise "leaf" (yaprak) olarak isimlendirilir. Buna göre bir öğrenci 48, üç öğrenci 50-60 arasında, 4 öğrenci 60-70 arasında not almıştır. Notu 75 olan iki öğrenci vardır. Ayrıca en yüksek notun 95 olduğunu ve 80-90 arasında not alan 2 öğrenci olduğunu görüyoruz.  
:::

::: {#exm-stem2}

Beygir gücü veri kümesinin dal-ve-yaprak çizimini hazırlayınız.

Bu veri kümesinde otomobillerin beygir gücü 52 ile 335 arasında değerler almaktadır. Onlar ve yüzler basamağını "dal", birler basamağını "yaprak" olarak seçersek: 
```{r}
stem(beygir_gucu, scale = 3)
```

grafiğin olası tüm basamakları içerdiğini ve boşluklar oluştuğunu görüyoruz. `scale = 1` seçeneğini kullanarak grafiği daha kompakt bir şekilde çizebiliriz: 

```{r}
stem(beygir_gucu, scale = 1)
```
Bu grafikte "0" 95'ten küçük iki basamaklı gözlemleri içerir. Bu değerler, 52, 62, 65, 66, 66, 91, ve 93, grafikte sırasıyla, 5, 6, 7, 7, 7, 9, ve 9 "yaprak" değerleriyle gösterilmiştir. Benzer şekilde grafikte yer alan 1 dalları 95 (dahil) ile 200 (hariç) arasındaki gözlemleri temsil etmektedir.  1 dal ve 0 yaprak değeri yaklaşık olarak 100 beygir gücünü, 1 dal ve 1 yaprak değeri yaklaşık 110 beygir gücünü göstermektedir. Diğer değerlerde benzer şekilde yorumlanabilir. Sıralanmış veriler: 
```{r}
sort(beygir_gucu)
```
En yüksek değerin (335) dal-ve-yaprak grafiğinde 3 dal ve 4 yaprak değeri ile temsil edildiğine dikkat ediniz. 

::: 

::: {#exm-stem3}
Türkiye'de il düzeyinde mutluluk endeksinin dal-ve-yaprak yaprak çizimi aşağıdaki gibidir: 
```{r}
stem(mutluluk$mutluluk)
```
Buna göre minimum ve maksimum mutluluk endeksleri sırasıyla 42 ve 78 olarak ölçülmüştür. Değerlerin 55-65 arasında yoğunlaştığı görülebilir. 
Stem basamağının tekrar etmesini istemiyorsak scale=0.5 seçilebilir: 
```{r}
stem(mutluluk$mutluluk, scale=0.5)
```
Bu grafik verilerin sayısal özet istatistikleri ile birlikte yorumlanabilir: 
```{r}
summary(mutluluk$mutluluk)
```
::: 


### Histogram

Sayısal değerler alan bir veri kümesinin dağılımını görselleştirmenin yaygın olarak kullanılan bir yolu gözlemlerin sınıflara ayrılması ve her sınıfa giren gözlem sayısının grafiğinin çizilmesidir. Bu grafik türüne histogram adı verilir.  

Histogram, gözlemleri belirli aralıklara böler ve her aralıktaki gözlem sayısını ya da yüzdesini bir çubuk grafiği olarak gösterir. Bunun için genellikle aşağıdaki adımlar izlenir: 

- Değerler aralığını bulun.

- Verileri belirli ve (genel olarak) birbirine eşit sınıflara bölün (gruplayın).

- Her sınıftaki gözlem sayısını hesaplayın.

- Her sınıf ya da aralık için bir çubuk oluşturun ve yüksekliğini o aralıktaki gözlem sayısına (frekans ya da sıklık) göre ayarlayın.


```{r}
#| label: fig-hist1
#| fig-cap: "Histogram sınıf sayısına duyarlıdır"
#| fig-subcap: 
#|   - "Sınıf sayısı çok az"
#|   - "Sınıf sayısı çok fazla"
#| layout-ncol: 2
#| fig-width: 4
#| fig-height: 3
#| echo: false 
set.seed(234567)
z <- rnorm(100)
hist(z, breaks=2, xlab="", ylab="Frekans", main="", xlim = c(-3,3))
hist(z, breaks=40, xlab="", ylab="Frekans", main="", xlim = c(-3,3))  
```
Histogram çizimindeki en önemli kararlardan biri sınıf ya da aralık sayısının belirlenmesidir. @fig-hist1 bir veri kümesi için farklı sınıf sayısı tercihlerini göstermektedir. Sınıf sayısı gereğinden az belirlenirse verilerdeki dağılım bilgisi kaybolur. Benzer şekilde sınıf sayısı çok yüksek belirlenirse çubuk sayısı artar, sınıflar arasında boşluklar oluşur ve dağılım fazla inişli çıkışlı olur. 


```{r}
#| label: fig-hist2
#| fig-cap: "Histogramda ideal sınıf seçimi"
#| fig-subcap: 
#|   - "Sınıf sayısı = 6"
#|   - "Sınıf sayısı= 11"
#| layout-ncol: 2
#| fig-width: 4
#| fig-height: 3
#| echo: false 
hist(z, breaks=6, xlab="", ylab="Frekans", main="", xlim = c(-3,3))
hist(z, breaks=11, xlab="", ylab="Frekans", main="", xlim = c(-3,3))  
```
@fig-hist2 aynı veri kümesi için sınıf sayısının 6 ve 11 olduğu iki durumu göstermektedir. Her iki sınıf sayısı için histogramın şeklinin yaklaşık olarak simetrik olduğunu görüyoruz. Sınıf sayısını ya da sınıf aralıklarını deneme yanılma ile belirlemek de mümkündür. Pratikte gözlem sayısına bağlı olarak sınıf sayısını belirleyebiliriz. 

Histogramdaki sınıf sayısını belirlemek için çeşitli yardımcı formüller önerilmiştir. Sturges formülü, verinin büyüklüğüne bağlı olarak histogramın optimal aralık sayısını aşağıdaki formüle göre hesaplar: 
$$
h = 1+\log_2(n)
$$
Burada $h$ sınıf sayısı ve $n$ gözlem sayısıdır. Bu formül,daha büyük veri kümeleri için daha fazla aralık ve daha küçük veri kümeleri için daha az aralık önerir.

Freedman-Diaconis kuralı, bir histogramın aralık sayısını belirlemek için kullanılan bir başka yöntemdir. Bu kural, veri setinin dağılımını ve büyüklüğünü dikkate alarak histogram aralıklarını belirler. Freedman-Diaconis kuralı şu şekildedir:

$$
bw = 2~IQR(x)~ n^{-1/3}
$$
Burada $bw$ aralık genişliğini, IQR ise kartiller aralığını temsil etmektedir ($Q_3-Q_1$). 

Scott kuralı, bir histogramın aralık sayısını belirlemek için bir başka yöntemdir. Bu kural, veri setinin standart sapmasını ve büyüklüğünü dikkate alarak histogram aralıklarını belirler.
$$
bw=3.5sd(x)n^{-1/3}
$$
Burada $sd(x)$ verilerin örneklem standart sapmasını göstermektedir. 

```{r}
#| label: fig-carpiklik1
#| fig-cap: "Dağılımın çarpıklığı" 
#| echo: false 
set.seed(1) 
n <- 10000
a <- rbeta(n, 10,2) 
c <- rbeta(n, 2,10) 
b <- rbeta(n, 10,10) 
par(mfrow = c(1, 3))  # 1 satır, 3 sütunlu bir çizim alanı oluşturur
hist(a, main = "Sola Çarpık, c<0", ylab = "", col = "lightblue", xlim=c(0,1))
hist(b, main = "Simetrik, c=0", ylab = "", col = "lightblue", xlim=c(0,1))
hist(c, main = "Sağa Çarpık, c>0", ylab = "", col = "lightblue", xlim=c(0,1))
```

Histogramın (dağılımın) biçimi ile çarpıklık katsayısı ($c$) ilişkilidir. Çarpıklık katsayısı $c$'nin 0 olması dağılımın simetrik olduğu duruma işaret eder (@fig-carpiklik1 (b)). Çarpıklık katsayısının pozitif olması, yani pozitif çarpıklık, dağılımın sağ kuyruğunun sola göre daha uzun olduğunu gösterir (@fig-carpiklik1 (c)). Negatif çarpıklık ise sol kuyruğun sağa göre daha uzun olduğunu ifade eder (@fig-carpiklik1 (a)).

::: {#exm-hist1}

Mutluluk verileri için önerilen sınıf sayılarını hesaplayalım: 
```{r}
sturges <- nclass.Sturges(mutluluk$mutluluk)
scott <- nclass.scott(mutluluk$mutluluk)
fd <- nclass.FD(mutluluk$mutluluk)
c(Sturges = sturges, Scott=scott, Friedman_Diaconis=fd)
```


```{r}
#| label: fig-mutlulukhist
#| fig-cap: "Histogram: Türkiye'de illerin mutluluk düzeyi" 
#| echo: false 
hist(mutluluk$mutluluk,
     breaks = 8, 
     xlab = "Mutluluk endeksi", 
     ylab = "Frekans", 
     main = "")
```
@fig-mutlulukhist mutluluk endeksinin histogramını göstermektedir. Sınıf sayısı 8 olarak belirlenmiştir. Bu histograma göre mutluluk düzeyinin merkezi eğiliminin 60 civarında olduğunu söyleyebiliriz. Mutluluk düzeyi azaldıkça ve arttıkça frekans azalmaktadır. Bu veri kümesinde ortalama ve medyan, sırasıyla, 61 ve 60 olarak bulunmuştu:
```{r}
summary(mutluluk$mutluluk)
```


`R`'da histogramın çiziminde kullanılan istatistikleri görmek istersek aşağıdaki kodu çalıştırabiliriz:  
```{r}
hist_mutluluk <- hist(mutluluk$mutluluk, breaks = 8, plot = FALSE)
str(hist_mutluluk)
```

`hist()` fonksiyonu birbirine eşit aralıklı sınıfları (breaks) ve her sınıfa düşen gözlem sayısını (counts) gösterir. Sınıf (bin) genişliği 5 birimdir. Gri renkte gösterilen dikdörtgenin uzunluğu (y ekseni) o sınıfa düşen gözlem sayısı ile orantılıdır. Sınıf aralıklarının tanımı  $(a, b]$  (`right = TRUE`) ya da $[a,b)$ (`right = FALSE`) olarak seçilebilir.  

Yoğunluk (density) her sınıfa düşen gözlem sayısının (counts) gözlem sayısı ve sınıf genişliğine oranıyla bulunur. Örneğin 40-45 aralığında sadece 1 gözlem vardır. Toplam gözlem sayısı 81 ve sınıf genişliği 5 olduğu için yoğunluk 
```{r}
1/81/5
```
yaklaşık 0.00247 olarak bulunur. 

`$mids` sınıfların orta noktalarını göstermektedir. 
:::  

Sayısal değerler alan bir değişkenin yoğunluk grafiği düzleştirilmiş histogram olarak yorumlanabilir. Sınıf aralıkları daraldıkça (ya da sınıf sayısı arttıkça) histogram yoğunluk fonksiyonuna yaklaşır. 

```{r}
#| label: fig-duzhist
#| fig-cap: "Düzleştirilmiş histogram ya da yoğunluk fonksiyonu"
#| fig-subcap: 
#|   - " "
#|   - " "
#|   - " "
#|   - " "
#| layout-ncol: 2
#| fig-width: 4
#| fig-height: 3
#| echo: false 
set.seed(2345)
z <- rnorm(10000)
hist(z, breaks=4, xlab="", ylab="Frekans", main="") 
hist(z, breaks=10, xlab="", ylab="Frekans", main="")  
hist(z, breaks=30, xlab="", ylab="Frekans", main="")  
hist(z, breaks=80, freq = FALSE, xlab="", ylab="Yoğunluk", main="", col = "white") 
lines(density(z), col="blue", lwd=2) 
```

@fig-duzhist histogram ve yoğunluk arasındaki ilişkiyi göstermektedir. Bu grafikte sınıf sayısı arttıkça histogramın yoğunluk fonksiyonuna yaklaştığına dikkat ediniz (bkz. @fig-duzhist-4). Histogram yorumunda olduğu gibi dağılımın merkezine doğru yaklaştıkça yoğunluk artmaktadır. Görece daha az sıklıkta gerçekleşen değerler için yoğunluk daha düşük değerler alır. İzleyen bölümlerde buradan hareketle olasılıkları nasıl hesaplayabileceğimizi öğreneceğiz. 

`R` `density()` fonksiyonunu kullanarak yoğunlukları hesaplayabilir ve görselleştirebiliriz. 

::: {#exm-hist2}
İllere göre mutluluk endeksinin yoğunluk grafiğini çiziniz. 

```{r}
#| label: fig-yogmutlu
#| fig-cap: "Yoğunluk grafiği: Türkiye'de illerin mutluluk düzeyi" 
#| echo: false 
plot(density(mutluluk$mutluluk), main="")
```
Yoğunluk ya da düzleştirilmiş histograma göre gözlem değerleri 55-65 arasında "yoğunlaşmaktadır" (@fig-yogmutlu). Sol ve sağ kuyruklara doğru gidildikçe yoğunluk azalmaktadır. 

Histogram ve yoğunluğu birlikte de çizebiliriz (bkz. @fig-yogmutlu2) 
```{r}
#| label: fig-yogmutlu2
#| fig-cap: "Yoğunluk grafiği: Türkiye'de illerin mutluluk düzeyi" 
#| echo: false  
hist(mutluluk$mutluluk,
     breaks = 8, freq = FALSE,
     xlab = "Mutluluk endeksi", 
     ylab = "Yoğunluk", 
     main = "")
lines(density(mutluluk$mutluluk), col="blue")
```

Yoğunluk fonksiyonunun detayları için yardım dosyasına bakınız, `?density()` 
::: 

::: {#exm-hist3}
`hane_ornek` veri kümesinde yer alan `aylik_harcama` değişkeninin histogramını ve yoğunluk fonksiyonunu çiziniz. Özet istatistiklerle birlikte yorumlayınız. Ayrıca, 0.1, 0.90, 0.95 ve 0.98 yüzdelik değerlerini hesaplayınız ve yorumlayınız. 

```{r}
load("Data/hane_ornek.RData")

sturges <- nclass.Sturges(hane_ornek$aylik_harcama)
scott <- nclass.scott(hane_ornek$aylik_harcama)
fd <- nclass.FD(hane_ornek$aylik_harcama)
c(Sturges = sturges, Scott=scott, Friedman_Diaconis=fd)
```

`breaks=100` ile histogramı ve yoğunluk fonksiyonunu çizelim. X ekseninin sınırlarını (0, 15000) olarak belirleyelim. 

```{r}
#| label: fig-harcamayog
#| fig-cap: "Hanehalkı harcama dağılımı" 
#| echo: false 
medyan <- median(hane_ornek$aylik_harcama)
ortalama <- mean(hane_ornek$aylik_harcama)

hist(hane_ornek$aylik_harcama,
     breaks = 100, freq = FALSE, 
     xlab = "Aylık hane harcaması, TL", 
     ylab = "Yoğunluk", 
     main = "", xlim = c(0,15000), ylim = c(0, 0.0004))
lines(density(hane_ornek$aylik_harcama), col="black", lwd=2,)

abline(v = medyan, col = "blue", lwd = 2, lty = 2)
abline(v = ortalama, col = "red", lwd = 2, lty = 2)

# Medyan ve ortalama değerlerini etiketleme
text(medyan, 0.0003, paste("Medyan = \n", round(medyan, 2)), col = "blue", adj = c(1, -0.5))
text(ortalama, 0.0003, paste("Ortalama =", round(ortalama, 2)), col = "red", adj = c(-0.1, 1))
```
Özet istatistikler: 
```{r}
summary(hane_ornek$aylik_harcama)
```
Histogram ve yoğunluk grafiğinden de görüleceği gibi (bkz. @fig-harcamayog) aylık hane harcamaları **sağa çarpık** bir dağılıma sahiptir. Örneklem ortalaması (3261 TL) medyan hane harcamasından (2584 TL) daha büyüktür. Hanelerinin yaklaşık % 75'inin aylık harcaması 3948 TL'den küçüktür. 

```{r}
quantile(hane_ornek$aylik_harcama, p=c(0.1, 0.9, 0.95, 0.98))
```
Hanelerin % 10'u aylık yaklaşık 1108 TL'den daha az harcamaktadır. Dağılımın diğer ucunda, hanelerin % 5'i 7802 TL'den daha fazla, % 2'si ise 10869 TL'den daha fazla harcamaktadır.
::: 


```{r}
#| label: fig-histkurtosis
#| fig-cap: "Dağılımların basıklığı"
#| fig-subcap: 
#|   - "Basık (platykurtic) dağılım"
#|   - "Normal (mesokurtic) dağılım"
#|   - "Sivri (leptokurtic) dağılım" 
#| layout-ncol: 3
#| echo: false 
# Platykurtic distribution example
set.seed(123)
data_flat <- runif(1000, min = 30, max = 70) # Uniform distribution
hist(data_flat, breaks = 20, xlab="", main = "kurtosis=1.81", col = "lightblue")
# Mesokurtic (normal) distribution example
set.seed(123)
data_normal <- rnorm(1000, mean = 50, sd = 10)
hist(data_normal, breaks = 20, xlab="", main = "kurtosis=2.93", col = "lightgreen")
# Leptokurtic distribution example
set.seed(123)
data_speaky <- c(rnorm(500, mean = 50, sd = 5), rnorm(500, mean = 50, sd = 2))
hist(data_speaky, breaks = 20, xlab="", main = "kurtosis=4.43", col = "lightcoral")
```

Veri dağılımlarını tanımlarken önemli bir özellik de basıklıktır. Basıklık, dağılımın tepe noktasının sivriliği ya da basıklığı ile ilgilidir. Yani dağılımın uç değerlerde (kuyruklarda) yoğunlaşıp yoğunlaşmadığını gösterir. Basıklık, dağılımların uç noktalarındaki gözlem sayısına göre 3 temel kategoriye ayrılabilir:

1. Düz Dağılımlar (Platykurtic): Basık dağılımlar, merkezi bölge dışında çok fazla gözlem bulunmayan ve uç değerlerin sayısının az olduğu dağılımlardır. Bu tür dağılımlarda histogramın tepe noktası geniş ve düz olur (@fig-histkurtosis-1). Böyle dağılımlarda kurtosis (basıklık) katsayısı 3'ten küçüktür.   

2. Normal Dağılımlar (Mesokurtic): Bir normal dağılım, basıklık açısından ortalama bir durumu gösterir. Dağılımın tepe noktası çok sivri ya da çok basık değildir. Normal dağılımın basıklık değeri 3 olarak tanımlıdır (@fig-histkurtosis-2). 

3. Sivri Dağılımlar (Leptokurtic): Uç değerlerde daha fazla gözlem içeren, tepe noktası oldukça sivri olan dağılımlar ise leptokurtik olarak adlandırılır. Bu dağılımlarda uç bölgelerdeki veriler normal dağılıma göre daha yoğundur. Böyle dağılımlar için kurtosis katsayısı 3'ten büyüktür (@fig-histkurtosis-3). 


```{r}
#| label: fig-getirihist
#| fig-cap: "BIST100 endeksinin günlük getirilerinin histogramı"
#| echo: false 
load("Data/bist100.rda")
ort <- mean(bist100$getiri, na.rm = TRUE)
sd <- sd(bist100$getiri, na.rm = TRUE)
hist(bist100$getiri, freq = FALSE, 
     xlim = c(-15, 15), ylim = c(0,0.3), breaks=100, 
     main="", xlab="")
#lines(density(rnorm(10000, mean=0, sd=1)))
lines(density(rnorm(10000, mean=ort, sd=sd)))
```

Basıklık kavramı dağılımın kuyruklardaki ve merkezdeki davranışını incelemede önemlidir. Özellikle verinin uçlardaki davranışı, çeşitli analizler için önemli olabilir. Örneğin bazı finansal varlık getirilerinin dağılımı kalın kuyruklu (leptokurtik) olma eğilimindedir. Böyle bir dağılım, normal dağılıma göre daha sivri bir tepe ve daha kalın kuyruklara sahip olur. @fig-getirihist BIST100 endeksinin günlük getirilerinin histogramını göstermektedir. Karşılaştırma amacıyla normal dağılımın yoğunluğu da grafiğe eklenmiştir. Bu getiriler için kurtosis değeri 8.07 olarak bulunmuştur. Normal dağılıma kıyasla, çoğu getiri değerinin ortalamaya yakın gerçekleştiğini, ancak uç olayların (aşırı kazanç veya kayıplar) normalden daha sık görüldüğünü söyleyebiliriz.  

```{r}
#| label: fig-modality
#| fig-cap: "Dağılımların modalliği"
#| fig-subcap: 
#|   - "Tek tepeli (Unimodal) dağılım "
#|   - "Çift tepeli (Bimodal) dağılım"
#|   - "Çok tepeli (Multimodal) dağılım" 
#| layout-ncol: 3
#| echo: false 
# Unimodal distribution example
set.seed(123)
data_unimodal <- rnorm(1000, mean = 50, sd = 10)
hist(data_unimodal, freq = FALSE,  
     breaks = 20, main = "", xlab="", col = "lightblue")
lines(density(data_unimodal))
# Bimodal distribution example
set.seed(123)
data_bimodal <- c(rnorm(500, mean = 40, sd = 5), rnorm(500, mean = 60, sd = 5))
hist(data_bimodal, freq = FALSE,  
     breaks = 20, main = "", xlab="", col = "lightgreen")
lines(density(data_bimodal))
# Multimodal distribution example
set.seed(123)
data_multimodal <- c(rnorm(300, mean = 30, sd = 5), 
                     rnorm(300, mean = 50, sd = 5), 
                     rnorm(300, mean = 70, sd = 5))
hist(data_multimodal, freq = FALSE,  
     breaks = 20, main = "", xlab="", col = "lightcoral")
lines(density(data_multimodal))
```

Histogram ya da yoğunluk grafikleri dağılımın simetriklik, sağa ve sola çarpıklık gibi özelliklerine ilişkin önemli bilgiler verir. Histogramların önemli bir başka özelliği de modalliktir. Modallik, dağılımda kaç tane tepe noktası (mod) olduğunu gösterir ve verilerin farklı alt gruplara bölünmesi gerektiğine işaret edebilir. 

Tek tepeli (unimodal) bir dağılımda, @fig-modality-1 da görüldüğü gibi, histogramın yalnızca bir belirgin tepe noktası vardır. Verinin büyük çoğunluğu belirli bir değerde toplanmıştır. İki tepe noktası olan dağılımlar çift tepeli olarak adlandırılır (@fig-modality-2). Bu tür dağılımlar, genellikle verinin iki farklı grup veya popülasyondan geldiğini gösterebilir. Örneğin, erkek ve kadın bireylerin boy dağılımı çift tepeli olabilir. Üç veya daha fazla tepe noktası olan dağılımlar çok modlu olarak adlandırılır (@fig-modality-3). Bu durum, verinin farklı alt gruplardan oluştuğunu veya karmaşık bir yapıya sahip olduğunu gösterebilir.
 


### Kutu çizimi



Kutu ya da kutu-bıyık (box-whiskers) çizimi olarak da isimlendirilen bu grafik verinin dağılımı hakkında bilgi verir ve beş-sayı özetinden hareketle oluşturulur.  **Beş-sayı özeti** aşağıdaki bileşenlerden oluşur:

1. **Minimum:** Verideki en küçük değer, $x_{(1)}$ sıra istatistiği.

2. **Birinci Çeyrek (Q1):** Verinin %25'inin altında kalan değeri gösterir (birinci kartil).

3. **Medyan (Q2):** Verinin ortasındaki değeri temsil eder. Verinin %50'si bu değerin altındadır (ikinci kartil).

4. **Üçüncü Çeyrek (Q3):** Verinin %75'inin altında kalan değeri gösterir (üçüncü kartil).

5. **Maksimum:** Verideki en büyük değer.


```{r}
#| label: fig-kutu0
#| fig-cap: "Kutu grafiği (uç değerlerin olmadığı durum)"
#| echo: false
#| 
set.seed(1)
x <- 5*rnorm(100)+100
# Boxplot çizimi
boxplot(x, horizontal = TRUE, main = "", ylim = c(85,115), 
        xlab = "X", col = "gray", frame = FALSE)

# Boxplot istatistiklerini hesaplayalım
box_stats <- boxplot.stats(x)

# Q1, Q2 (Medyan), Q3, min (whisker) ve max (whisker) değerlerini işaretleme
text(x = box_stats$stats[1], y = 0.9, labels = "Min", cex=0.9, col = "red", pos = 1)
text(x = box_stats$stats[2], y = 0.8, labels = "Q1", col = "blue", cex=0.9, pos = 1)
text(x = box_stats$stats[3], y = 0.8, labels = "Q2\n(Medyan)", cex=0.9, col = "black", pos = 1)
text(x = box_stats$stats[4], y = 0.8, labels = "Q3", col = "blue", cex=0.9, pos = 1)
text(x = box_stats$stats[5], y = 0.9, labels = "Maks", col = "red", cex=0.9, pos = 1)
```

@fig-kutu0 uç değerlerin (outlier) olmadığı durum için örnek bir kutu çizimini göstermektedir. Bu grafiğin bileşenleri şunlardır: 

- **Kutu:** Q1 ve Q3 arasında yer alır ve verinin ortanca %50'sini içerir. Kutunun içinde yer alan çizgi (dikey ya da yatay olabilir) medyanı gösterir. Buradan hareketle merkezi aralığı (IQR) kolayca değerlendirebiliriz. 

- **Bıyıklar (Whiskers):** Kutunun her iki ucundan minimum ve maksimum değerlere kadar uzanır. Eğer tüm gözlem değerleri $1.5\times IQR$ aralığı içindeyse alt ve üst bıyık noktaları aynı zamanda minimum ve maksimum değerlerdir. Ancak bu aralığın dışında değerler varsa bunlar ayrıca gösterilir. 

- **Uç (aşırı) Değerler (Outliers):** Q1-1.5*IQR'den küçük veya Q3+1.5*IQR'den büyük olan değerlerdir. Bunlar kutu ve bıyıkların dışında tekil noktalar olarak gösterilir. Örneğin @fig-kutu1 alt ve üst uç değerlerin olduğu bir veri kümesine ilişkin kutu çizimini göstermektedir. Bu grafikte alt ve üst bıyık ötesindeki noktalar uç değerleri göstermektedir. 


```{r}
#| label: fig-kutu1
#| fig-cap: "Kutu grafiği (uç değerlerin olduğu durum)"
#| echo: false

set.seed(1)
x <- 5*rnorm(400)+100
# Boxplot çizimi
boxplot(x, horizontal = TRUE, main = "", ylim = c(85,115), 
        xlab = "X", col = "gray", frame = FALSE)

# Boxplot istatistiklerini hesaplayalım
box_stats <- boxplot.stats(x)

# Q1, Q2 (Medyan), Q3, min (whisker) ve max (whisker) değerlerini işaretleme
text(x = box_stats$stats[1], y = 0.9, labels = "Alt bıyık", cex=0.9, col = "red", pos = 1)
text(x = box_stats$stats[2], y = 0.8, labels = "Q1", col = "blue", cex=0.9, pos = 1)
text(x = box_stats$stats[3], y = 0.8, labels = "Q2\n(Medyan)", cex=0.9, col = "black", pos = 1)
text(x = box_stats$stats[4], y = 0.8, labels = "Q3", col = "blue", cex=0.9, pos = 1)
text(x = box_stats$stats[5], y = 0.9, labels = "Üst bıyık", col = "red", cex=0.9, pos = 1)
```



R'da kutu çizimi için `boxplot()` fonksiyonu kullanılabilir (bkz. @fig-kutumutluluk): 
```{r}
#| label: fig-kutumutluluk
#| fig-cap: "Türkiye'de illerin mutluluk endeksinin kutu grafiği"
#| echo: true
boxplot(x = mutluluk$mutluluk,
        xlab = "",  
        ylim = c(40,80),
        ylab = "Mutluluk endeksi"
        )
```
Mutluluk endeksinin kutu grafiğini 5-sayı özeti ile birlikte yorumlayabiliriz. 
```{r}
# min Q1 median Q3 max
fivenum(mutluluk$mutluluk)
summary(mutluluk$mutluluk)
```
Buna göre minimum mutluluk düzeyi yaklaşık olarak 42, ilk kartil 56.54, medyan 60.39, üçüncü kartil yaklaşık 66 ve maksimum mutluluk yaklaşık 78'dir. Medyan ve ortalamanın birbirine yakın olması mutluluğun yaklaşık olarak simetrik dağıldığına işaret etmektedir. Kutu çiziminde medyan çizgisinin kartiller aralığın gösteren dikdörtgeni yaklaşık iki eşit parçaya ayırdığına dikkat ediniz. 

### Keman grafiği 

Keman çizimi, kutu-bıyık grafiğinin bir uzantısıdır ve veri dağılımını daha ayrıntılı bir şekilde görselleştirir. Bu grafik türü, son dönemde popülerleşmiştir ve verinin yoğunluk dağılımını da göstermektedir. Keman çiziminin bileşenleri şunlardır:

- **Kutu:** Kutu-bıyık grafiğinde olduğu gibi Q1, Q2 (medyan) ve Q3'ü içerir.

- **Bıyıklar:** Minimum ve maksimum değerleri gösterir.

- **Yoğunluk Eğrisi:** Verinin dağılımını görselleştirir ve verinin yoğun olduğu bölgeleri daha geniş, seyrek olduğu bölgeleri ise daha dar gösterir.


Keman grafiği, verinin dağılımını ve yoğunluklarını detaylı bir şekilde anlamamıza yardımcı olur. Bu grafik türü, verinin merkezi eğilimi ve yayılımı, asimetri veya çarpıklık, aşırı değerler ve potansiyel veri anormallikleri hakkında bilgi verir. 

Keman grafiği, kutu-bıyık grafiğine ek olarak verinin yoğunluk dağılımını da içerdiği için, veri analizi ve görselleştirme açısından daha zengin bilgiler sunar.

```{r}
#| label: fig-keman1
#| fig-cap: "Keman grafiği"
#| echo: true
# Örnek veri seti
veri <- x
# Keman grafiği
library(ggplot2)
df <- data.frame(veri = veri)
ggplot(df, aes(x = veri, y = "")) + 
  geom_violin(fill = "lightblue", color = "black") +
  geom_boxplot(width = 0.3, fill = "gray") +
  theme_minimal() +
  labs(title = "Keman Grafiği", x = "Değerler", y = "")
```

@fig-keman1 örnek bir keman grafiğini göstermektedir. Bu grafiğin oluşturulmasında `ggplot2()` paketi kullanılmıştır. Kutu çiziminin yanı sıra yoğunluk fonksiyonunu şekli de görülmektedir. Buradan haraketle dağılımın yaklaşık olarak simetrik olduğunu söyleyebiliriz. 

```{r}
#| label: fig-keman2
#| fig-cap: "Keman grafiği: iki tepeli dağılım"
#| echo: true
# Örnek veri seti
set.seed(123)
x1 <- rnorm(100, mean = 20, sd = 5)
x2 <- rnorm(100, mean = 40, sd = 5)
x <- c(x1, x2)
# Keman grafiği
library(ggplot2)
df2 <- data.frame(x = x)
ggplot(df2, aes(x = x, y = "")) + 
  geom_violin(fill = "lightblue", color = "black") +
  geom_boxplot(width = 0.3, fill = "gray") +
  theme_minimal() +
  labs(title = "Keman Grafiği", x = "Değerler", y = "")
```

Kutu çiziminin bir eksikliği dağılımın simetrikliği dışında dağılımın şekli hakkında bilgi içermemesidir. Bazı dağılımlarda birden fazla tepe noktası olabilir. Keman çizimi özellikle bu durumda faydalı olabilir. Örnek olarak @fig-keman2 iki tepeli bir yoğunluğa sahip olan bir değişkenin keman grafiğini göstermektedir.  


## İki Değişken Arasındaki İlişkinin Betimlenmesi 

Şimdiye kadar bir değişkenin merkezi eğilimi, yayıklığı, ve dağılımının biçimine ilişkin çeşitli görsel ve sayısal araçları öğrendik. Bu bölümde iki değişken arasındaki ilişkinin nasıl görselleştirilebileceğini ve özetlenebileceğini öğreneceğiz. 

Elimizde sürekli değerler alan iki değişkene ilişkin gözlemler olsun. Örneğin, 10 öğrencinin derse devam oranları ile notları aşağıdaki gibidir:  
```{r}
# notlar ve devam oranı
devam <- c(80, 75, 70, 90, 91, 60, 86, 95, 83, 70)
basari <- c(75, 78, 50, 80, 81, 60, 80, 90, 76, 80)

# Veri çerçevesi oluşturma
veri1 <- data.frame(`Öğrenci` = 1:10, 
                   `Devam_oranı` = devam, 
                   `Başarı` = basari)
print(veri1)
```
Bu veri kümesinde gözlem birimi öğrencilerdir. Her bir öğrenci için derse devam oranı ile not çiftini gözlemliyoruz. Birinci öğrencinin %80 devam oranı ile 100 üzerinden 75 başarıyla dersi tamamladığını görüyoruz. İkinci öğrenci %75 devam ve 78 puan, üçüncü öğrenci %70 devam ve 50 puan değerlerine sahiptir. Bu veri kümesini görsel olarak özetlemenin en pratik yolu X ve Y eksenlerinde bu değişkenlerin olduğu ve gözlem değerlerinin noktalarla ifade edildiği bir serpilme grafiği çizmektir:   
```{r}
#| label: fig-notlar1
#| fig-cap: "Ders devam oranı ve başarı arasındaki serpilme çizimi"
 
plot(x = veri1$`Devam_oranı`, # x ekseni
     y = veri1$`Başarı`,      # y ekseni
     col = "black",           # renk = siyah
     pch = 16,                # sembol=içi dolu nokta
     cex = 1.2,               # sembol büyüklüğü
     main ="",                # başlık
     ylim=c(50,100),          # y ekseninin sınırları
     xlim=c(50,100),          # x ekseninin sınırları
     panel.first = grid(),    # grid çizgileri
     xlab = "Derse devam oranı, %",          # x etiketi
     ylab = "Başarı (100 puan üzerinden)"    # y etiketi  
     ) 
text(veri1$`Devam_oranı`, veri1$`Başarı`, 
     labels = veri1$`Öğrenci`,  # öğrenci no ekle
     cex = 0.9,
     pos = 3)
```

@fig-notlar1 öğrencilerin derse devam oranları ile başarı düzeyleri arasındaki ilişkinin serpilme çizimini göstermektedir. Gözlem çiftlerini betimleyen noktaların üzerindeki sayılar öğrencilerin numaralarıdır. Örneğin birinci öğrencinin %80 devam oranı ile 100 üzerinden 75 başarıyla dersi tamamladığını görüyoruz. İkinci öğrenci %75 devam ve 78 puan, üçüncü öğrenci %70 devam ve 50 puan değerlerine sahiptir.  Bu grafikten hareketle devam oranı arttıkça başarının yükseldiğini söyleyebiliriz. İki değişken arasında aynı yönlü (pozitif) bir doğrusal ilişki olduğu görülmektedir. 

::: {#exm-serpilme1}
`hane_ornek` veri kümesinde yer alan `aylik_gelir` ve  `aylik_harcama` değişkenlerinin serpilme çizimini oluşturunuz.  

**Çözüm**



```{r}
#| label: fig-serpilme-harc1
#| fig-cap: "Serpilme grafiği: aylık gelir ve harcama"
load("Data/hane_ornek.RData")
plot(x = hane_ornek$aylik_gelir, y = hane_ornek$aylik_harcama, 
     col = "black", 
     panel.first = grid(),
     xlab = "Aylık hane geliri, TL", 
     ylab = "Aylık hane harcaması, TL"
     ) 
```

@fig-serpilme-harc1 hanehalkı aylık ortalama gelir ve harcama değerlerinin serpilme grafiğini göstermektedir. Genel olarak gelir düzeyi ile harcama arasında pozitif bir ilişki olduğu söylenebilse de grafiğin sol alt kısmında, gelir ve harcamanın düşük olduğu alanlarda veri noktalarının yoğunlaştığını görülmektedir. Bu, daha fazla hanenin düşük gelir ve düşük harcama seviyelerinde olduğunu gösterir. Gerçekten de özet istatistiklerden 
```{r}
summary(hane_ornek$aylik_harcama)
summary(hane_ornek$aylik_gelir)
```
hanelerin %75'inin 4530 TL'den az gelire sahip oldukları görülebilir. @fig-serpilme-harc2 gelir düzeyi 5000 TL'den az olan alt küme için serpilme çizimini göstermektedir. Bu grafikte gelir ve harcamanın düşük olduğu bölgelerde veri noktalarının yoğunlaşması daha belirgin hale gelmiştir. Gelirine oranla harcaması çok yüksek hanelerin de olduğu görülmektedir. 


```{r} 
#| label: fig-serpilme-harc2
#| fig-cap: "Aylık geliri 5000 TL'den az olan hanelerde gelir ve harcama"
hane_ornek_alt1 <- subset(hane_ornek, aylik_gelir<5000)
plot(x = hane_ornek_alt1$aylik_gelir, 
     y = hane_ornek_alt1$aylik_harcama, 
     col = "black",  
     panel.first = grid(),
     xlab = "Aylık hane geliri, TL", 
     ylab = "Aylık hane harcaması, TL"
     ) 
```

:::



::: {#exm-serpilme2}

## Serpilme ve dağılım grafiği 

Serpilme çizimine değişkenlerin dağılımlarını da eklemek mümkündür. Bunun için `car` paketinde yer alan `scatterplot()` fonksiyonu kullanılabilir: 
```{r}
#| label: fig-serpilme-boxplot
#| fig-cap: "Serpilme çizimi ve kutu grafiği"
library(car)
set.seed(1234)
x = rnorm(1000) + 10
y = 2 + 3*x + 2*rnorm(100)
scatterplot(y ~ x, smooth = FALSE)
```
@fig-serpilme-boxplot bu veri kümesinin serpilme çizimini x ve y değişkenlerinin kutu çizimleriyle birlikte vermektedir. Bu iki değişken arasında pozitif yönlü doğrusal bir ilişki olduğunu görüyoruz. Ayrıca, x'in merkezinin 10 civarında ve dağılımının simetrik olduğunu söyleyebiliriz. Benzer şekilde y'nin merkezi 30 civarında ve simetrik bir biçime sahiptir.  
:::

Serpilme çizimlerini inceleyerek değişkenler arasındaki ilişkinin yönü hakkında çıkarımda bulunabiliriz. Görsel araçlar, verilerin faydalı bir özetini sunar, ancak bu özetler sayısal özetlerle desteklenmelidir. İki sayısal değişken arasındaki ilişkiyi anlamak için kullanılan temel istatistiksel araçlar kovaryans ve korelasyondur. Kovaryans, iki değişkenin birlikte nasıl değiştiğini ölçer, pozitif veya negatif yönlü ilişkiler hakkında bilgi verir. Korelasyon ise, bu ilişkinin gücünü ve yönünü, ölçekten bağımsız olarak ifade eder. Bu sayede, değişkenler arasındaki ilişkiyi daha açık bir şekilde ortaya koyabiliriz.

### Kovaryans 

Kovaryans, iki değişkenin birlikte nasıl değiştiğini ölçen bir istatistiktir. İki değişkenin ortalamalarından sapmalarının çarpımlarının ortalaması olarak hesaplanır. Kovaryans pozitifse, değişkenler birlikte artma eğilimindedir; negatifse, bir değişken artarken diğeri azalma eğilimindedir.

::: {#def-popcov}

## Anakütle kovaryansı 

İki değişken arasındaki anakütle kovaryansı
$$
\sigma_{xy} \equiv \text{Cov}(X, Y) = \frac{1}{N} \sum_{i=1}^{N} (X_i - \mu_x)(Y_i - \mu_y)
$$ {#eq-kovpop}
olarak tanımlanır ve $\sigma_{xy}$ ya da $\mbox{Cov}(X, Y)$ ile gösterilir. Burada $N$ anakütlenin (evrenin) boyutunu, $\mu_x$ ve $\mu_y$ bu değişkenlerin anakütle ortalamalarını ifade etmektedir. $\mbox{Cov}(X, Y)$ pozitif, negatif, ya da 0 olabilir. 
::: 

::: {#def-samplecov}

## Örneklem kovaryansı 

Bir anakütleden çekilmiş $n$ boyutlu bir veri kümesinden hareketle örneklem kovaryansını tanımlayabiliriz: 
$$
\hat{\sigma}_{xy} \equiv \widehat{\text{Cov}(x, y)} = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})
$$ {#eq-kovornek}
Burada $x_i$ ve $y_i$, rassal değişkenlerin i. gözlemlerini, $\bar{x}$ ve $\bar{y}$ bu değişkenlerin örneklem ortalamalarını, ve $n$ gözlem sayısını ifade etmektedir. Örneklem kovaryansı bilinmeyen anakütle kovaryansını tahmin etmekte kullanılabilir. 
:::  


| Öğrenci  | $x$            |  $y$       | $x - \bar{x}$ | $y - \bar{y}$ | $(x - \bar{x}) \times (y - \bar{y})$ |
|:--------:|:--------------:|:----------:|:-------------:|:-------------:|:------------------------------------:|
| 1       | 80              | 75         | 0             | 0             | 0                                    |
| 2       | 75              | 78         | -5            | 3             | -15                                  |
| 3       | 70              | 50         | -10           | -25           | 250                                  |
| 4       | 90              | 80         | 10            | 5             | 50                                   |
| 5       | 91              | 81         | 11            | 6             | 66                                   |
| 6       | 60              | 60         | -20           | -15           | 300                                  |
| 7       | 86              | 80         | 6             | 5             | 30                                   |
| 8       | 95              | 90         | 15            | 15            | 225                                  |
| 9       | 83              | 76         | 3             | 1             | 3                                    |
| 10      | 70              | 80         | -10           | 5             | -50                                  |
| **Toplam** | **800**      | **750**    | **0**         | **0**         | **859**                              |
: Kovaryans hesaplama tablosu: derse devam ve başarı {#tbl-kov1}

@tbl-kov1 derse devam oranı ile başarı düzeyi arasındaki kovaryansı hesaplamaktadır. Bu tabloda $x$ derse devam oranını, $y$ başarı düzeyini (not) göstermektedir. Tablonun altındaki toplamlardan hareketle devam oranının ortalamasının $\bar{x}=80$, başarı düzeyinin ortalamasının $\bar{y}=75$ olduğu görülebilir. Dördüncü ve beşinci sütunlarda ortalamadan farklar hesaplanmıştır. Son sütunda ise ortalamalardan farkların çarpımları yer almaktadır. Buradan hareketle bu iki değişken arasındaki örneklem kovaryansı kolayca hesaplanabilir: 

\begin{align*}
\widehat{\text{Cov}(X,Y)} &= \frac{1}{10-1} \sum_{i=1}^{10} (x_i - \bar{x})(y_i - \bar{y}) \\
&= \frac{1}{9} \left[ (80-80)(75-75) + (75-80)(78-75) + \ldots + (70-80)(80-75) \right] \\
&= \frac{1}{9} \left[ 0 + (-5)(3) + \ldots + (-10)(5) \right] \\
&= \frac{1}{9} \left[ 0 -15 + \ldots -50 \right] \\
&= \frac{1}{9} \times (859) \\
&\approx 95.4
\end{align*}

`R`'da `cov()` fonksiyonu ile de bu hesaplama yapılabilir: 
```{r}
cov(veri1$Devam_oranı, veri1$Başarı)
```

```{r}
#| label: fig-kov1
#| fig-cap: "Pozitif kovaryans"
#| echo: false

set.seed(123)
x1 <- rnorm(20)
y1 <- 2 * x1 + rnorm(20)
x_mean1 <- mean(x1)
y_mean1 <- mean(y1)
x_diff1 <- x1 - x_mean1
y_diff1 <- y1 - y_mean1

# Negatif ilişki
x2 <- rnorm(20)
y2 <- -2 * x2 + rnorm(20)
x_mean2 <- mean(x2)
y_mean2 <- mean(y2)
x_diff2 <- x2 - x_mean2
y_diff2 <- y2 - y_mean2

# Sıfır ilişki
x3 <- rnorm(20)
y3 <- rnorm(20)
x_mean3 <- mean(x3)
y_mean3 <- mean(y3)
x_diff3 <- x3 - x_mean3
y_diff3 <- y3 - y_mean3


# Pozitif ilişki grafiği
#par(pty="s")
plot(x_diff1, y_diff1, 
     pch = 19, col = "blue", cex = 1,
       xlab = expression(X - bar(X)), ylab = expression(Y - bar(Y)),
       main = "", xlim = c(-4, 4), ylim = c(-4, 4))
  abline(h = 0, v = 0, col = "gray", lty = 2)
  arrows(0, 0, x_diff1, y_diff1, col = "red", length = 0.1, lty = 2)
text(2, 2, "Bölge I (+, +)", pos = 4, cex = 0.8)  # (+, +) etiketi
text(-2, 2, "Bölge II (-, +)", pos = 2, cex = 0.8)  # (-, +) etiketi
text(-2, -2, "Bölge III (-, -)", pos = 2, cex = 0.8)  # (-, -) etiketi
text(2, -2, "Bölge IV (+, -)", pos = 4, cex = 0.8)  # (+, -) etiketi
```

İki değişken arasındaki kovaryansın işareti ilişkinin yönü hakkında bilgi verir. Ancak büyüklüğü ölçü birimlerine bağlı olduğu için genellikle yorumlanmaz. Kovaryans formülünde yer alan ortalamalardan farkların çarpımının işareti ilişkinin yönünü belirler. @fig-kov1 kovaryansın pozitif işaretli olduğu durumu görselleştirmektedir. Bu grafikte X ve Y eksenleri ortalamalardan farkları göstermektedir. Buna göre X ortalamanın üzerindeyken, yani ortalama farkı pozitifken Y de ortalamanın üzerinde olma eğilimindeyse (bölge 1) her iki fark pozitif işaretli ve çarpımları da pozitif işaretli olur. Diğer durumda X ortalamanın altındayken Y de ortalamanın altında olma eğilimindeyse her iki işaret negatif ve çarpımları pozitif olur. Sonuç olarak ortalamada bu değişkenlerin aynı yönde hareket ettikleri yani kovaryanslarının pozitif olduğu söylenebilir. 

```{r}
#| label: fig-kov2
#| fig-cap: "Negatif kovaryans"
#| echo: false
# Negatif ilişki grafiği 
plot(x_diff2, y_diff2, pch = 19, col = "blue", cex = 1,
       xlab = expression(X - bar(X)), ylab = expression(Y - bar(Y)),
       main = "", xlim = c(-5, 5), ylim = c(-5, 5), asp = 1)
  abline(h = 0, v = 0, col = "gray", lty = 2)
  arrows(0, 0, x_diff2, y_diff2, col = "red", length = 0.1, lty = 2)
text(2, 2, "Bölge I (+, +)", pos = 4, cex = 0.8)  # (+, +) etiketi
text(-2, 2, "Bölge II (-, +)", pos = 2, cex = 0.8)  # (-, +) etiketi
text(-2, -2, "Bölge III (-, -)", pos = 2, cex = 0.8)  # (-, -) etiketi
text(2, -2, "Bölge IV (+, -)", pos = 4, cex = 0.8)  # (+, -) etiketi
```
 @fig-kov2 ise tersi durumu göstermektedir. X ortalamanın altındayken Y kendi ortalamasının üzerinde değerler alıyorsa (bölge II) çarpımın işareti negatif olacaktır. Diğer durumda X ortalamanın üzerindeyken Y ortalamanın altındaysa (bölge IV) çarpımın işareti negatif olacaktır. Tüm gözlem noktalarında eğilim bu şekildeyse kovaryans negatif işaretli olur. Merkezlere olan uzaklık büyüdükçe kovaryans değeri de mutlak olarak büyüyecektir. 

```{r}
#| label: fig-kov3
#| fig-cap: "Sıfır kovaryans"
#| echo: false
# Sıfır ilişki grafiği 
plot(x_diff3, y_diff3, pch = 19, col = "blue", cex = 1,
       xlab = expression(X - bar(X)), ylab = expression(Y - bar(Y)),
       main = " ", xlim = c(-2, 2), ylim = c(-2, 2), asp = 1)
  abline(h = 0, v = 0, col = "gray", lty = 2)
  arrows(0, 0, x_diff3, y_diff3, col = "red", length = 0.1, lty = 2)
text(2, 1, "Bölge I (+, +)", pos = 4, cex = 0.8)  # (+, +) etiketi
text(-2, 1, "Bölge II (-, +)", pos = 2, cex = 0.8)  # (-, +) etiketi
text(-2, -1, "Bölge III (-, -)", pos = 2, cex = 0.8)  # (-, -) etiketi
text(2, -1, "Bölge IV (+, -)", pos = 4, cex = 0.8)  # (+, -) etiketi 
```

 @fig-kov3 X ile Y arasında ilişkinin olmadığı durumu göstermektedir. Bu durumda ortalamadan farkların orijin çevresinde tesadüfi bir şekilde dağıldığına dikkat ediniz. 

### Korelasyon 

Korelasyon, iki değişken arasındaki lineer ilişkinin gücünü ve yönünü ölçen bir istatistiktir. Pearson korelasyon katsayısı en yaygın kullanılan korelasyon ölçüsüdür. Değerler -1 ile +1 arasında değişir. +1 mükemmel pozitif ilişkiyi, -1 mükemmel negatif ilişkiyi, 0 ise ilişkisizliği ifade eder.

::: {#def-popcorr}

## Anakütle korelasyon katsayısı

Bir anakütle için iki değişken arasındaki korelasyon katsayısı 
$$
\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y} \equiv \frac{\text{Cov}(X, Y)}{\sigma_x \sigma_y}
$$ {#eq-korpop}
formülüyle hesaplanır. Burada $\sigma_{xy}$ iki değişken arasındaki anakütle kovaryansını, $\sigma_x$ ve $\sigma_y$ bu değişkenlerin anakütle standart sapmalarını ifade etmektedir.
:::  

::: {#def-samplecorr}

## Örneklem korelasyon katsayısı 

Örneklem korelasyon katsayısı aşağıdaki gibi tanımlanır: 
$$
r_{xy}\equiv \hat{\rho}_{xy} = \frac{\widehat{\text{Cov}(X, Y)}}{s_x s_y}
$$
Burada $\widehat{\text{Cov}(X, Y)}$ iki değişken arasındaki örneklem kovaryansını, $s_x$ ve $s_y$ bu değişkenlerin örneklem standart sapmalarını ifade etmektedir.
:::  

Örneklem korelasyon katsayısı $r_{xy}$, iki sayısal değişken arasındaki doğrusal ilişkinin gücünü ve yönünü ölçen bir istatistiktir. Her zaman $-1$ ile $1$ arasında bir değer alır:

- $r = 1$: Mükemmel pozitif doğrusal ilişki. Bir değişken arttıkça diğer değişken de artar.

- $r = -1$: Mükemmel negatif doğrusal ilişki. Bir değişken arttıkça diğer değişken azalır.

- $r = 0$: Değişkenler arasında **doğrusal bir ilişki** yoktur.

Korelasyonun işareti kovaryansın işaretine bağlıdır. Pozitif korelasyon durumunda X ve Y değerleri arttıkça, veri noktaları ortalama etrafında yukarı doğru bir eğim gösterir ve farkların çarpımı pozitif olur. Negatif korelasyon durumunda ise X değeri arttıkça Y değerleri azalır; veri noktaları ortalama etrafında aşağı doğru bir eğim gösterir ve farkların çarpımı negatif olur. Sıfır korelasyon durumunda ise X ve Y arasında belirgin bir ilişki yoktur. Veri noktaları etrafında rastgele dağılır ve farkların çarpımının ortalaması sıfıra yakın olma eğilimindedir. 


```{r echo=FALSE}
#| label: fig-korelasyon1
#| fig-cap: "X ile Y arasındaki korelasyon ve serpilme çizimleri"
#| fig-height: 8


# Gerekli paketleri yükleyelim
library(MASS)

# Korelasyon katsayıları
cor_values <- c(-0.8, -0.5, 0, 0.5, 0.8, 1)

# Grafik penceresini bölmek
par(mfrow=c(3, 2))

# Her bir korelasyon katsayısı için veri oluşturma ve görselleştirme
set.seed(123)
for (cor_val in cor_values) {
  # Korelasyon matrisi oluşturma
  sigma <- matrix(c(1, cor_val, cor_val, 1), 2, 2)

  # Veri oluşturma
  data <- mvrnorm(200, mu = c(0, 0), Sigma = sigma)

  # Dağılma diyagramı oluşturma
  plot(data[,1], data[,2],
       main=paste("Korelasyon: ", cor_val),
       xlab="X", ylab="Y",
       pch=19, col="gray")
}
```


Korelasyon katsayısı $1$'e ya da $-1$'e yaklaştıkça doğrusal ilişkinin güçlendiğini, $0$'a yaklaştıkça zayıfladığını söyleyebiliriz. @fig-korelasyon1 farklı korelasyon değerlerine sahip değişken çiftlerinin serpilme çizimlerini göstermektedir. Korelasyon katsayısı azaldıkça veya arttıkça, veri noktalarının doğrusal bir çizgi etrafında daha sıkı bir şekilde kümelendiği görülebilir. Özellikle korelasyonun 0 olduğu grafikte, veri noktalarının belirgin bir doğrusal ilişki göstermediğine dikkat ediniz. Özetlersek, bu grafikte 

- Korelasyon $-0.8$: Güçlü negatif ilişki. X değeri arttıkça Y değeri azalma eğilimindedir.

- Korelasyon $-0.5$: Orta düzeyde negatif ilişki. X değeri arttıkça Y değeri genel olarak azalmaktadır, ancak ilişki daha zayıftır.

- Korelasyon $0$: Hiçbir doğrusal ilişki yoktur. X ve Y değerleri arasında belirgin bir ilişki gözlemlenmemektedir.

- Korelasyon $0.5$: Orta düzeyde pozitif ilişki. X değeri arttıkça Y değeri genel olarak artmaktadır.

- Korelasyon $0.8$: Güçlü pozitif ilişki. X değeri arttıkça Y değeri artma eğilimindedir.

- Korelasyon $1$: Mükemmel pozitif doğrusal ilişki. X ve Y değerleri tamamen doğrusal bir ilişki içerisindedir; X değeri arttıkça Y değeri de sabit bir oranda artmaktadır.





::: {#exm-kor1}
@tbl-kov1 verisinden hareketle derse devam oranı ile başarı notu arasındaki Pearson korelasyon katsayısını hesaplayınız. 

**Çözüm**

Örneklem korelasyon katsayısını hesaplayabilmek için kovaryansı ve değişkenlerin standart sapmalarını bulmamız gerekir. Örneklem kovaryansını 95.4 olarak bulmuştuk. Derse devam oranının örneklem standart sapması 11.136 ve başarı oranının standart sapması 11.528 olarak bulunabilir. Böylece örneklem korelasyon katsayısı 

$$
r_{xy} = \frac{\widehat{\text{Cov}(X, Y)}}{s_x s_y} = \frac{95.4}{(11.136)(11.528)} = 0.74
$$
olur. 
`cor()` fonksiyonu ile 
```{r}
cor(veri1$Devam_oranı,  veri1$Başarı)
```
Buradan hareketle derse devam oranı ile başarı düzeyi arasında güçlü pozitif bir ilişki olduğunu söyleyebiliriz. 
:::

::: {#exm-anscombe}

## Görselleştirmenin önemi, Anscombe veri kümesi

```{r}
library(datasets)
anscombe
```
Bu veri kümesinde yer alan $(x1,y1),\ldots,(x4,y4)$ değişken çiftleri arasındaki korelasyon yaklaşık olarak 0.816'dır: 
```{r}
kor_x1_y1 <- cor(anscombe$x1, anscombe$y1)
kor_x2_y2 <- cor(anscombe$x2, anscombe$y2)
kor_x3_y3 <- cor(anscombe$x3, anscombe$y3)
kor_x4_y4 <- cor(anscombe$x4, anscombe$y4)
cbind(kor_x1_y1, kor_x2_y2, kor_x3_y3, kor_x4_y4)
```


```{r}
#| label: fig-anscombe
#| fig-cap: "Görselleştirmenin önemi: Anscombe dörtlüsü"
#| echo: false 
#| warning: false

library(tidyverse)
library(grid)
library(gridExtra)
p1 <- ggplot(anscombe) +
  geom_point(aes(x1, y1), color = "blue", size = 1.5) +
  scale_x_continuous(breaks = seq(0,20,2)) +
  scale_y_continuous(breaks = seq(0,12,2)) +
  expand_limits(x = 0, y = 0) +
  labs(x = "x1", y = "y1",
       title = "Veri 1" ) +
  theme_bw()
p2 <- ggplot(anscombe) +
  geom_point(aes(x2, y2), color = "blue", size = 1.5) +
  scale_x_continuous(breaks = seq(0,20,2)) +
  scale_y_continuous(breaks = seq(0,12,2)) +
  expand_limits(x = 0, y = 0) +
  labs(x = "x2", y = "y2",
       title = "Veri 2" ) +
  theme_bw()
p3 <- ggplot(anscombe) +
  geom_point(aes(x3, y3), color = "blue", size = 1.5) +
  scale_x_continuous(breaks = seq(0,20,2)) +
  scale_y_continuous(breaks = seq(0,12,2)) +
  expand_limits(x = 0, y = 0) +
  labs(x = "x3", y = "y3",
       title = "Veri 3" ) +
  theme_bw()
p4 <- ggplot(anscombe) +
  geom_point(aes(x4, y4), color = "blue", size = 1.5) +
  scale_x_continuous(breaks = seq(0,20,2)) +
  scale_y_continuous(breaks = seq(0,12,2)) +
  expand_limits(x = 0, y = 0) +
  labs(x = "x4", y = "y4",
       title = "Veri 4" ) +
  theme_bw()
grid.arrange(grobs = list(p1, p2, p3, p4), 
             ncol = 2, 
             top = "Anscombe's Quartet")
```
@fig-anscombe bu veri kümelerini göstermektedir. Her bir veri kümesi aynı ortalama ve varyansa  ve benzer korelasyon katsayısına sahiptir. Ancak, görsel olarak incelendiğinde bu verilerin oldukça farklı dağılımlar ve ilişkiler sergilediği görülmektedir. 

- Veri 1: x1 ve y1 arasında pozitif yönde doğrusal bir ilişki bulunmaktadır. 
- Veri 2: x2 ve y2 arasında doğrusal olmayan (kuadratik) bir ilişki vardır. 
- veri 3: x3 ve y3 doğrusal bir ilişkiye sahip gibi görünmekle birlikte bir uç değer vardır. 
- Veri 4: x4, bir değer dışında, aynı değere sahiptir. Bu değer dışlanırsa (19) x4'ün varyansı sıfır olur. 
::: 

Anscombe'nin Dörtlüsü, sadece korelasyon katsayısına dayanarak değişkenler arasındaki ilişkiyi anlamanın sınırlamalarını ortaya koymaktadır.  Korelasyon katsayısı, iki değişken arasındaki doğrusal ilişkiyi ölçer. Ancak, bazı değişkenler doğrusal olmayan ilişkiler gösterebilir. Bu durumlarda, doğrusal olmayan ilişkileri tanımlamak ve analiz etmek için başka yöntemler kullanmak gerekebilir. Ayrıca, uç değerler korelasyon katsayısını önemli ölçüde etkileyebilir. Korelasyon katsayısı değişkenlerin dağılımı hakkında bilgi vermez. Aynı korelasyon katsayısına sahip olsalar da, yukarıda gösterildiği gibi, dağılımda önemli farklılıklar olabilir. 



### Korelasyon katsayısının geometrik anlamı 

Korelasyon, iki vektör arasındaki açının kosinüsü olarak düşünülebilir. $\mathbf{a}$ ve $\mathbf{b}$ iki vektör olsun. Bu iki vektörün iç çarpımı 
$$
\mathbf{a} \cdot \mathbf{b} = \sum_{i=1}^{n} a_i b_i
$$
ve vektör normları (ya da uzunlukları)
$$
\| \mathbf{a} \| = \sqrt{\sum_{i=1}^{n} a_i^2}
$$
ve 
$$
\| \mathbf{b} \| = \sqrt{\sum_{i=1}^{n} b_i^2}
$$
olarak tanımlıdır. İki vektör arasındaki açının kosinüsü iç çarpım ve uzunluklar ile aşağıdaki gibi tanımlanabilir: 
$$
\cos(\theta) = \frac{\mathbf{a} \cdot \mathbf{b}}{\| \mathbf{a} \| \| \mathbf{b} \|}
$$
$0\leq \theta\leq \pi$ iki vektör arasındaki açıdır. Kosinüs fonksiyonunun tanımı gereği $\cos(\theta)$ her zaman $-1$ ile $1$ arasında değerler alır. 

```{r}
#| echo: false
#| eval: false
#| output: false

# Define the sequence from 0 to pi
x <- seq(0, pi, length.out = 100)

# Calculate cos(x)
y <- cos(x)

# Plot cos(x)
plot(x, y, type = "l", col = "blue", lwd = 2, 
     xlab = "x", ylab = "cos(x)", main = "Plot of cos(x) from 0 to pi")

# Highlight points 0, pi/2, and pi
points(c(0, pi/2, pi), cos(c(0, pi/2, pi)), col = "red", pch = 19)

# Add labels to highlighted points
text(0, 1, "0", pos = 2)
text(pi/2, cos(pi/2), expression(frac(pi, 2)), pos = 3)
text(pi, -1, expression(pi), pos = 4)

# Add gridlines
grid()
```



$x$ ve $y$ gözlem değerlerini iki vektör olarak düşünülebilir. Ortalamadan farklar vektörlerini $\mathbf{a} = (x_i - \bar{x})$ ve $\mathbf{b} = (y_i - \bar{y})$ şeklinde tanımlarsak 
$$
r = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2} \sqrt{\sum_{i=1}^{n} (y_i - \bar{y})^2}}\equiv \cos(\theta) 
$$
korelasyon katsayısının $\cos(\theta)$ olduğunu görebiliriz. 

  - $r = 1$: İki değişken arasında mükemmel pozitif doğrusal ilişki vardır. Bu durumda, iki vektör aynı yöndedir ve açı $\theta = 0$'dır, dolayısıyla $\cos(0) = 1$.

  - $r = -1$: İki değişken arasında mükemmel negatif doğrusal ilişki vardır. Bu durumda, iki vektör zıt yöndedir ve açı $\theta = \pi$ ya da $180^\circ$'dir. Dolayısıyla $\cos(\pi) = -1$ olur.
  
  - $r = 0$: İki değişken arasında doğrusal bir ilişki yoktur. Bu durumda, iki vektör arasındaki açı $\theta = \frac{\pi}{2}$ ya da $90^\circ$'dir ve $\cos\left(\frac{\pi}{2}\right) = 0$ olur.  


**Cauchy-Schwarz Eşitsizliği**: İki vektör arasındaki nokta çarpımı, bu vektörlerin normlarının çarpımına eşit veya daha küçüktür:
$$
    \left| \sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y}) \right| \leq \sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2} \sqrt{\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

Burada, eşitlik durumu, iki değişken arasında tam doğrusal bir ilişki olduğunda (pozitif veya negatif) ortaya çıkar.


## Çözümlü Alıştırmalar

::: {#exr-betimsel0}

::: 


::: {#exr-medyan}

Bir sayısal vektörü girdi olarak alan ve medyanı hesaplayan bir `R` fonksiyonu yazınız. 

**Çözüm**

```{r}
# Medyanı hesaplayan fonksiyon
# x = nümerik vektör
medyan <- function(x) { 
  # Girdinin sayısal olup olmadığını kontrol etme
  if (!is.numeric(x)) {
    stop("Girdi sayısal bir vektör olmalıdır.")
  }
  sirali_veriler <- sort(x)   # sırala
  n <- length(sirali_veriler) # verinin boyutu 
  if (n %% 2 == 1) {
    # Tek sayıdaki veri seti için
    medyan <- sirali_veriler[(n+1)/2]
  } else {
    # Çift sayıdaki veri seti için
    ortadaki1 <- sirali_veriler[n/2]
    ortadaki2 <- sirali_veriler[(n/2)+1]
    medyan <- (ortadaki1 + ortadaki2)/2
  }
  return(medyan)
}
medyan(gpa)
medyan(gpa2)
```
Burada `(n %% 2)` işlemi $n$'in 2'ye bölümünden kalanı verir. Çift sayılar için 0, tek sayılar için ise 1 değerini alır. 
:::


::: {#exr-betimsel1}

- Aşağıda verilen iki veri kümesini kullanarak ortalama, medyan, Q1, Q3, IQR ve aralıkları hesaplayın. İşlemleri önce kendiniz bir hesap makinesi yardımıyla yapınız. Daha sonra R programını kullanarak sonuçları karşılaştırınız. 
```{r}
dataset1 <- c(48, 49, 50, 51, 52, 48, 49, 50, 51, 52)
dataset2 <- c(40, 45, 48, 50, 52, 55, 58, 60, 45, 47)
```

**Çözüm**

```{r}
ortalama <- mean(dataset1)
medyan <- median(dataset1)
q1 <- quantile(dataset1, 0.25)
q3 <- quantile(dataset1, 0.75)
iqr <- IQR(dataset1)
stats1 <- rbind(ortalama, medyan, q1, q3, iqr)
colnames(stats1) <- "dataset1"
stats1
```


```{r}
ortalama <- mean(dataset2)
medyan <- median(dataset2)
q1 <- quantile(dataset2, 0.25)
q3 <- quantile(dataset2, 0.75)
iqr <- IQR(dataset2)
stats2 <- rbind(ortalama, medyan, q1, q3, iqr)
colnames(stats2) <- "dataset2"
stats2
```

```{r}
cbind(stats1, stats2)
```
Her iki veri kümesinin ortalaması aynıdır, medyan değerleri birbirine çok yakındır. Ancak ikinci veri setinin değişkenliği daha fazladır. Merkezi yayıklığı ölçen IQR ikinci veri kümesinde 8.75, birincisinde ise 2 olarak bulunmuştur. 

::: 

::: {#exr-betimsel2}

Rassal sayılar çekilerek bir veri kümesi oluşturulmuştur: 
```{r}
# örnek veri seti simülasyonu
set.seed(123)
x1 = rnorm(100, mean=5, sd=1.2)
x2 = rnorm(100, mean=0, sd=0.8)
grup = sample(c("A", "B", "C"), 100, replace = TRUE)
y = 2 + 2*x1 - 3*x2 + 5*(grup=="B") + 8*(grup=="C") + rnorm(100) 
#
df <- data.frame(y, x1, x2, grup) # veri çerçevesini oluştur
head(df)
```
Buna göre aşağıdaki soruları yanıtlayın. 

  a) Bu veri kümesinde yer alan x1, x2 ve y değişkenlerinin özet istatistiklerini hesaplayın ve yorumlayın.
  a) y'nin özet istatistiklerini gruplara göre hesaplayın ve yorumlayın.
  a) Gruplara göre kutu çizimlerini oluşturun ve yorumlayın.
  
**Çözüm**:

  a) Değişkenlenlerin özet istatistikleri 
  
```{r}
summary(df)
```
Ortalama ve medyan değerlerinden hareketle y ve x1'in yaklaşık olarak simetrik, x2'nin ise hafif sağa çarpık olduğunu söyleyebiliriz. 

  
  a) Gruplara göre y'nin betimsel istatistikleri:
  
```{r}
summary(df$y[grup=="A"])
summary(df$y[grup=="B"])
summary(df$y[grup=="C"])
```
Bu sonuçlara göre grup A en düşük ortalama ve medyana, grup C ise en yüksek ortalama ve medyana sahiptir. Grup B ikisinin arasındadır. Bunun yanı sıra birinci ve üçüncü kartillerin de benzer şekilde A'dan C'ye doğru arttığını görüyoruz. 

  
  a) Gruplara göre kutu çizimi:  
  
```{r}
boxplot(formula = y ~ grup,
        data = df, at = c(0, 0.5, 1.0), ylim=c(0,30),
        horizontal = FALSE, 
        frame.plot = FALSE,  
        boxwex = .3, # daha dar kutu
        boxfill ="gray80",
        whiskcol = "gray70", 
        boxcol = "grey70",
        outcol = "grey70", 
        whisklty = 1,
        outpch = 20, # uç değerler nokta 
        outcex = 0.8, # uç değer boyutu 
        medlwd = 1.0       
)
```
Önceki kısımda belirttiğimiz gibi y'nin medyanı grup C'de en yüksek değeri almaktadır. A grubunda y yaklaşık olarak simetrik dağılırken, B grubunda hafif sola, C grubunda ise sağa çarpıktır. 

Bu grafiği `plot()` fonksiyonu ile de çizebiliriz: 
```{r}
plot(as.factor(df$grup), df$y)
```
::: 



::: {#exr-scatter1}

`mtcars` veri kümesinde yer alan araç ağırlığı (`wt`) ve yakıt verimliliği (`mpg`, galon başına mil) değişkenlerinin kovaryansını ve korelasyon katsayısını hesaplayınız. Serpilme grafiğini oluşturarak yorumlayınız. 

**Çözüm**:

```{r}
# mtcars veri setini yükleyelim
data(mtcars)

# Kovaryans ve korelasyon hesaplama
cov_value <- cov(mtcars$mpg, mtcars$wt)
cor_value <- cor(mtcars$mpg, mtcars$wt)
cov_value
cor_value
```

```{r}
# Dağılma diyagramı oluşturma ve kovaryans ve korelasyon değerlerini ekleme
plot(mtcars$wt, mtcars$mpg, 
     main=paste("Serpilme grafiği: Araç Ağırlığı ve Yakıt Verimliliği\n",
                "Kovaryans: ", round(cov_value, 2), ", Korelasyon: ", round(cor_value, 2)),
     xlab="Ağırlık (1000 lbs)", 
     ylab="Mil/Gallon (mpg)",
     pch=19)
```

Bu sonuçlara göre otomobilin ağırlığı ile yakıt verimliliği arasında negatif yönlü güçlü bir ilişki olduğunu söyleyebiliriz (korelasyon katsayısı $-0.87$ bulundu). Aracın ağırlığı arttıkça yakıt verimliliği, yani birim yakıt (galon) başına gidilen yol (mil cinsinden) azalmaktadır. Buradan hareketle büyük otomobillerin yakıt tüketimi bakımından daha verimsiz olduğu söylenebilir. 

:::  


::: {#exr-kor1}
`mutluluk` veri kümesinde yer alan `saglik_tatmin` (sağlık tatmin düzeyi) ve `mutluluk` (mutluluk düzeyi) değişkenlerinin serpilme grafiğini çiziniz ve korelasyon katsayısını hesaplayınız. 

**Çözüm**: 

```{r}
load("Data/mutluluk.rda")
```

```{r}
cor(mutluluk$saglik_tatmin, mutluluk$mutluluk)
```

```{r}
plot(mutluluk$saglik_tatmin, mutluluk$mutluluk, 
     col = rgb(0,100,0,50, maxColorValue = 255), # renk kontrolü
     pch = 16,                                   # nokta şekli
     main ="Serpilme çizimi",                    # başlık
     xlab = "Sağlık tatmin düzeyi", 
     ylab = "Mutluluk endeksi"
     )
```
Bu sonuçlara göre sağlık tatmin düzeyi ile mutluluk arasında orta düzeyde pozitif bir doğrusal ilişki vardır (korelasyon yaklaşık 0.6). Serpilme çiziminden de görüldüğü gibi sağlık tatmin düzeyi arttıkça mutluluk düzeyi de artmaktadır. 

İl düzeyinde mutluluk düzeyi, o ilde yaşayan bireylerin ortalama sağlık tatminleri, ve sosyal hayat tatmin düzeyleriyle de ilişkilidir. Bunu göstermek için aşağıdaki gibi korelasyon matrisi oluşturabiliriz: 
```{r}
cor(mutluluk[,c(15,41,42)])
```
Bu matrisin hücreleri o satır ve sütundaki değişkenler arasındaki korelasyon katsayısını göstermektedir (ana köşegen her zaman 1 olur). Buna göre sosyal hayat tatmin düzeyi ile mutluluk endeksi arasındak korelasyon katsayısı 0.68'dir. Bu değişkenler arasında serpilme çizimlerini de `plot()` fonksiyonu ile oluşturabiliriz: 
```{r}
plot(mutluluk[,c(15,41,42)])
```

::: 



::: {#exr-datasaurus}
Bu alıştırmada verileri görselleştirmenin önemini vurgulamak amacıyla geliştirilmiş `datasauRus` veri kümesini inceleyeceğiz. Önce veri kümesini yükleyin: 
```{r}
# install.packages("datasauRus")
library(datasauRus)
data(datasaurus_dozen)
```

Bu veri kümesinde yer alan değişken çiftleri için korelasyon katsayısını hesaplayın, serpilme çizimlerini oluşturun ve yorumlayın. 

**Çözüm**: 

```{r}
#| warning: false
library(dplyr)
datasaurus_groups <- datasaurus_dozen %>% group_by(dataset)
```

```{r}
#| label: fig-datasaurus
#| fig-cap: "Görselleştirmenin önemi: Datasaurus verileri"
#| echo: false 
#| warning: false
library(ggplot2)
ggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset)) +
  geom_point() +
  facet_wrap(~dataset, ncol = 3) +
  theme_minimal() +
  labs(title = "Datasaurus Verileri",
       x = "X Değeri",
       y = "Y Değeri")
```

Korelasyonları hesaplayalım: 
```{r}
datasaurus_correlations <- datasaurus_dozen %>%
  group_by(dataset) %>%
  summarize(correlation = cor(x, y))
print(datasaurus_correlations)
```

Her bir çift için korelasyon katsayısı yaklaşık -0.06'dır. Neredeyse sıfır korelasyon değeri, değişkenler arasında hiç bir ilişki olmadığı anlamına gelmez. Serpilme çizimlerinden de görüldüğü gibi ilişkilerin şekli belirgin biçimde farklıdır.  Anscombe Dörtlüsünde olduğu gibi, Datasaraus veri kümesi de korelasyon katsayısının tek başına verilerin tüm özelliklerini yansıtmakta yetersiz kalabileceğini göstermektedir. 


<!-- ```{r} -->
<!-- #| label: fig-datasaurus -->
<!-- #| fig-cap: "Görselleştirmenin önemi: Datasaurus verileri" -->
<!-- #| echo: false  -->
<!-- #| warning: false -->
<!-- library("ggplot2") -->
<!-- library("datasauRus") -->
<!-- ggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset))+ -->
<!--   geom_point() + -->
<!--   theme_void() + -->
<!--   theme(legend.position = "none")+ -->
<!--   facet_wrap(~dataset, ncol = 3) -->
<!-- ``` -->
::: 

## Problemler 


::: {#cnj-sayisalozet1}
Aşağıdaki soruları yanıtlayın. 

  a) Merkezi eğilim ölçülerini sıralayın ve kısaca açıklayın. Hangi durumda medyan tercih edilir? 
  a) Hangi tür verileri için geometrik ortalama uygun olabilir? 
  a) Bir firmanın satışları 4 yıllık bir dönemde %40 büyümüştür. Yıllık ortalama büyüme yüzde kaçtır? 
  a) "Aralık, uç değerlerden etkilenmeyen bir değişkenlik ölçüsüdür" Bu ifadeye katılır mısınız? Kısaca açıklayın. 
  a) Değişkenlik ölçüleri nelerdir? Kısaca açıklayın. 
::: 

::: {#cnj-sayisalozet1}
Büyük bir toplulukta IQ skorları ortalaması 100 standart sapması 10 olan bir dağılıma uymaktadır. 

  a) Çan biçimli bir dağılım varsayımı altında, gözlemlerin %95'inin içinde yer alacağı bir aralık oluşturun. 
  a) Dağılımın şeklinin bilinmediğini düşünelim. Gözlemlerin yüzde kaçı 1 ve 2 standart sapma içinde yer alır? 
::: 

::: {#cnj-betimsel0} 
Aşağıdaki tablonun sütunlarındaki her değişken için ortalama, medyan, mod, standart sapma, IQR, ve varyasyon katsayısını bulun. 

| X  |  Y | Z  |  A | B  |  C | D  |
|---|---|---|---|---|---|---|
| 0  | 5   |  -3 | 24   | 5  | 124 |  55 |
| 1  | 3   |  -2 | 30   | 5  | 85   | 64  |
| 0  | 0   |  -1 | 12   | 5  | 102   | 72   |
| 0  | 6   |  0  | 7    | 5  | 156   | 75    |
| 1  | 10  |  1  | 15   | 3  | 133   | 78   |
| 1  |  1  |  2  | 28   | 1  | 115   | 85   |

::: 

::: {#cnj-betimsel0a} 
Aşağıdaki veri kümesini düşünelim: 
$$
(51, 42, 51, 56, 54, 58, 49, 60, 52, 55, 52, 51, 49, 42, 44, 54, 50, 46, 53, 50, 47, 52, 49, 50, 49)
$$
Bilgisayar kullanmadan: 

  a) Dal-ve-yaprak çizimini oluşturun. 
  a) 5-sayı özet istatistiklerini hesaplayın.
  a) Kutu grafiğini çizin.
  a) 4 ya da 5 sınıftan oluşan frekans tablosunu hazırlayın ve histogramını çizin.  
:::  

::: {#cnj-betimsel0a} 
Aşağıdaki ifadelerin doğru/yanlış olup olmadıklarını belirtin ve kısaca açıklayın. 

  a) Medyan ortalamaya göre uç değerlere daha az duyarlıdır. 
  a) IQR  aralığa kıyasla uç değerlere daha az duyarlıdır. 
  a) Kovaryans her zaman -1 ile 1 arasında değerler alır. 
  a) Korelasyon katsayısının 0.9 olması iki değişken güçlü pozitif doğrusal ilişki olduğu anlamına gelir. 
  a) Kutu grafiği dağılımın modalliği (tepe sayısı) hakkında bilgi vermez. 
:::  

::: {#cnj-betimsel1} 
Çok sayıda öğrencinin katıldığı bir sınavın sonucuna ilişkin aşağıdaki yorumlar yapılıyor: 

  a) Öğrencilerin %70'i ortalamadan yüksek not almış. 
  a) Öğrencilerin %70'i medyandan yüksek not almış. 
  a) Öğrencilerin %60'ı medyandan düşük not almış.
  
Bu ifadelerden hangileri kesin olarak yanlıştır? Kısaca açıklayınız. 
::: 

::: {#cnj-betimsel2}
Ortalaması 10 standart sapması 2 olan 5 sayı oluşturun (bilgisayar kullanmayın). 
::: 

::: {#cnj-mutluluk} 

`gapminder` verilerini kullanarak aşağıdaki soruları yanıtlayınız:

  a) Doğumdaki yaşam beklentisi, `lifeExp`, değişkeninin 1952 yılı için histogramını çizin.  
  a) Aynı değişkenin 2007 yılındaki histogramını da çizin ve karşılaştırın. 
::: 

::: {#cnj-haneornek1} 
`hane_ornek.RData` verilerini kullanarak aşağıdaki soruları yanıtlayınız: 

  a) `sigara` hanede sigara içen varsa 1, yoksa 2 değerini alan bir kategorik değişkendir. Bunu kullanarak bir faktör değişkeni oluşturun. Hanelerin yüzde kaçında sigara içilmektedir? 
  a) Sigara içilen ve içilmeyen gruplar için ayrı ayrı özet istatistikleri oluşturun ve kutu grafiklerini çizin. Ortalama ve medyanı kullanarak bu iki grup arasında önemli farklar olup olmadığını tartışın.
  a) `ozel_sigorta` değişkeni hanehalkının özel sigortası varsa 1 yoksa 2 değerini almaktadır. Hanelerin ne kadarının özel sigortası vardır? 
  a) Özel sigortası olan ve olmayan hanelerde aylık gelir ve harcamanın özet istatistiklerini oluşturun, histogramlarını çizin ve yorumlayın. 
::: 

::: {#cnj-mutluluk} 

`mutluluk.RData` verilerini kullanarak aşağıdaki soruları yanıtlayınız:

  a) `ort_gun_kazanc` o ilde yaşayan bireylerin ortalama günlük kazançlarını göstermektedir. Bu değişkenin histogramını ve kutu grafiğini çizin. Özet istatistikleri hesaplayın ve grafiklerle birlikte yorumlayın. 
  a) `mutluluk` endeksi ile `ort_gun_kazanc` arasındaki korelasyon katsayısını bulun. Serpilme diagramını çizin ve yorumlayın. 
  a) Bu iki değişkenin varyasyon katsayılarını (CV) hesaplayın ve yorumlayın. 
::: 

